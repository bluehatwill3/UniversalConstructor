{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluehatwill3/UniversalConstructor/blob/main/Intelliemolife_now.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1O_ZJ2I6yVi",
        "outputId": "8eeceeb8-cbd3-49eb-b967-1aec2661b577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/670.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.8/670.8 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.5/430.5 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.3/539.3 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install Quantum, Neuromorphic, and AI libraries\n",
        "!pip install -q cirq qsimcirq brian2 google-generativeai cuda-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cirq\n",
        "import qsimcirq\n",
        "from brian2 import *\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. HIVE DATA PREPARATION (Full Dataset)\n",
        "# Format: [Synchrony, Haptic_Resonance]\n",
        "data_raw = np.array([\n",
        "    [0.998, 0.814], [0.998, 0.824], [0.999, 0.844], [0.996, 0.832], [0.999, 0.849],\n",
        "    [0.999, 0.858], [0.999, 0.885], [0.998, 0.840], [0.998, 0.784], [0.998, 0.851],\n",
        "    [0.998, 0.819], [0.998, 0.878], [0.997, 0.826], [0.999, 0.841], [0.999, 0.823],\n",
        "    [0.997, 0.831], [0.998, 0.816], [0.998, 0.850], [0.998, 0.839], [0.998, 0.835],\n",
        "    [0.998, 0.817], [0.999, 0.835], [0.998, 0.817], [0.999, 0.895], [0.999, 0.817],\n",
        "    [0.999, 0.839], [0.999, 0.790], [0.999, 0.766], [0.998, 0.878], [0.998, 0.797],\n",
        "    [0.998, 0.821], [0.998, 0.871], [0.999, 0.863], [0.999, 0.862], [0.999, 0.829],\n",
        "    [0.997, 0.869], [0.999, 0.874], [0.997, 0.799], [0.999, 0.897], [0.998, 0.769],\n",
        "    [0.997, 0.790], [0.999, 0.865], [0.999, 0.832], [0.999, 0.898], [0.998, 0.851],\n",
        "    [0.999, 0.848], [0.999, 0.868], [0.999, 0.867], [0.999, 0.819], [0.999, 0.811],\n",
        "    [0.999, 0.856], [0.998, 0.846], [0.998, 0.828], [0.999, 0.867], [0.999, 0.884],\n",
        "    [0.998, 0.847], [0.998, 0.806], [0.999, 0.836], [0.999, 0.853], [0.999, 0.823],\n",
        "    [0.999, 0.863], [0.999, 0.859], [0.998, 0.850], [0.999, 0.842], [0.999, 0.837],\n",
        "    [0.999, 0.849], [0.998, 0.850], [0.997, 0.788], [0.999, 0.858], [0.998, 0.822],\n",
        "    [0.998, 0.829], [0.999, 0.851], [0.999, 0.833], [0.998, 0.846], [0.999, 0.825],\n",
        "    [0.998, 0.860], [0.999, 0.842], [0.999, 0.864], [0.998, 0.814], [0.998, 0.841],\n",
        "    [0.998, 0.849], [0.999, 0.895], [0.998, 0.839], [0.999, 0.918], [0.999, 0.854],\n",
        "    [0.999, 0.861], [0.998, 0.812], [0.999, 0.864], [0.999, 0.814], [0.999, 0.858],\n",
        "    [0.999, 0.872], [0.997, 0.823], [0.999, 0.861], [0.999, 0.867], [0.999, 0.833],\n",
        "    [0.999, 0.801], [0.999, 0.901], [0.998, 0.845], [0.998, 0.808], [0.999, 0.821],\n",
        "    [0.997, 0.818], [0.999, 0.797], [0.999, 0.859], [0.998, 0.796], [0.998, 0.794],\n",
        "    [0.999, 0.862], [0.999, 0.852], [0.997, 0.902], [0.999, 0.824], [0.999, 0.832],\n",
        "    [0.999, 0.883], [0.999, 0.825], [0.998, 0.854], [0.998, 0.881], [0.999, 0.793],\n",
        "    [0.999, 0.838], [0.999, 0.868], [0.999, 0.873], [0.998, 0.818], [0.998, 0.840],\n",
        "    [0.999, 0.880], [0.999, 0.875], [0.999, 0.853], [0.999, 0.848], [0.999, 0.854],\n",
        "    [0.996, 0.827], [0.999, 0.804], [0.998, 0.872], [0.997, 0.775]\n",
        "])\n",
        "\n",
        "# Labels for training (1 = HIGH SYNCHRONY EVENT)\n",
        "labels = np.ones(len(data_raw))\n",
        "\n",
        "# 2. NEUROMORPHIC LAYER (Brian2)\n",
        "def get_neuromorphic_features(haptic_data):\n",
        "    start_scope()\n",
        "    tau = 10*ms\n",
        "    eqs = '''\n",
        "    dv/dt = (v0 - v) / tau : 1 (unless refractory)\n",
        "    v0 : 1\n",
        "    '''\n",
        "    # Each neuron in the group represents one cycle's haptic drive\n",
        "    G = NeuronGroup(len(haptic_data), eqs, threshold='v > 0.8', reset='v = 0', refractory=5*ms, method='exact')\n",
        "    G.v = 0\n",
        "    G.v0 = haptic_data # Direct haptic resonance input\n",
        "\n",
        "    spikemon = SpikeMonitor(G)\n",
        "    run(100*ms)\n",
        "\n",
        "    # Return normalized spike counts\n",
        "    counts = spikemon.count\n",
        "    if max(counts) == 0: return np.zeros(len(haptic_data))\n",
        "    return counts / max(counts)\n",
        "\n",
        "print(\"Simulating Neuromorphic Spiking Layer...\")\n",
        "snn_features = get_neuromorphic_features(data_raw[:, 1])\n",
        "\n",
        "# 3. QUANTUM FEATURE MAP (Cirq & Qsim)\n",
        "def get_quantum_features(synchrony_data):\n",
        "    qubits = [cirq.GridQubit(0, i) for i in range(2)]\n",
        "    simulator = qsimcirq.QSimSimulator()\n",
        "    quantum_results = []\n",
        "\n",
        "    for val in synchrony_data:\n",
        "        circuit = cirq.Circuit()\n",
        "        # Non-linear encoding: rotate qubit based on synchrony\n",
        "        theta = val * np.pi\n",
        "        circuit.append(cirq.ry(theta)(qubits[0]))\n",
        "        circuit.append(cirq.H(qubits[1]))\n",
        "        circuit.append(cirq.CNOT(qubits[0], qubits[1]))\n",
        "        circuit.append(cirq.measure(qubits[0], qubits[1], key='m'))\n",
        "\n",
        "        result = simulator.run(circuit, repetitions=100)\n",
        "        counts = result.histogram(key='m')\n",
        "        # Probability of state |11> (decimal 3)\n",
        "        prob_1 = counts.get(3, 0) / 100.0\n",
        "        quantum_results.append(prob_1)\n",
        "\n",
        "    return np.array(quantum_results)\n",
        "\n",
        "print(\"Computing Quantum Feature Map...\")\n",
        "q_features = get_quantum_features(data_raw[:, 0])\n",
        "\n",
        "# 4. MULTI-LAYER PERCEPTRON (Hybrid Fusion)\n",
        "class HybridMLP:\n",
        "    def __init__(self):\n",
        "        # 2 Input neurons (Q-Map, SNN-Spikes) -> 4 Hidden -> 1 Output\n",
        "        self.w1 = np.random.randn(2, 4)\n",
        "        self.b1 = np.zeros(4)\n",
        "        self.w2 = np.random.randn(4, 1)\n",
        "        self.b2 = np.zeros(1)\n",
        "        self.lr = 0.01\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.h = self.sigmoid(np.dot(x, self.w1) + self.b1)\n",
        "        self.o = self.sigmoid(np.dot(self.h, self.w2) + self.b2)\n",
        "        return self.o\n",
        "\n",
        "    def train(self, X, y, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for i in range(len(X)):\n",
        "                # Forward pass\n",
        "                target = y[i]\n",
        "                pred = self.forward(X[i])\n",
        "\n",
        "                # Simple MSE Loss calculation\n",
        "                loss = (target - pred)**2\n",
        "                total_loss += loss\n",
        "\n",
        "                # Backpropagation (Basic Gradient Descent)\n",
        "                error_o = (target - pred) * pred * (1 - pred)\n",
        "                error_h = error_o.dot(self.w2.T) * self.h * (1 - self.h)\n",
        "\n",
        "                # Update weights\n",
        "                self.w2 += self.lr * np.outer(self.h, error_o)\n",
        "                self.b2 += self.lr * error_o\n",
        "                self.w1 += self.lr * np.outer(X[i], error_h)\n",
        "                self.b1 += self.lr * error_h\n",
        "\n",
        "            if epoch % 200 == 0:\n",
        "                print(f\"Epoch {epoch}, Mean Loss: {total_loss/len(X)}\")\n",
        "\n",
        "# Stack simulated features for MLP input\n",
        "X_hybrid = np.column_stack((q_features, snn_features))\n",
        "\n",
        "# Initialize and train the MLP\n",
        "mlp = HybridMLP()\n",
        "print(\"Training Fusion MLP...\")\n",
        "mlp.train(X_hybrid, labels)\n",
        "\n",
        "# Results Analysis\n",
        "print(\"\\n--- Final Hybrid Analysis Results ---\")\n",
        "print(f\"Total Cycles Processed: {len(data_raw)}\")\n",
        "print(f\"Final Weights (Hidden to Out):\\n{mlp.w2}\")\n",
        "\n",
        "# Final Prediction Check\n",
        "print(\"\\nTesting for anomalies...\")\n",
        "test_stable = X_hybrid[0] # Take first cycle as stable test\n",
        "test_unstable = np.array([0.1, 0.1]) # High-entropy synthetic state\n",
        "\n",
        "print(f\"Stability Score (Recorded Cycle 3157): {mlp.forward(test_stable)[0]:.4f}\")\n",
        "print(f\"Stability Score (Hypothetical Anomaly): {mlp.forward(test_unstable)[0]:.4f}\")"
      ],
      "metadata": {
        "id": "ul45wuMmAYOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbntiWyu7B9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f687c31d-c1cc-41aa-bce3-75c7ab768906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import cuda\n",
        "# Configure Gemini\n",
        "genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "def get_satellite_params(tle_data):\n",
        "    prompt = f\"Analyze this Starlink TLE data: {tle_data}. Extract the mean motion and inclination. Suggest a neuron firing threshold (0.5-1.0) and a quantum rotation angle (0-3.14) based on orbital stability.\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osQyoy3_CEFA",
        "outputId": "decfa7d8-4b9a-483b-c073-9101b57fd268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Acceleration: [ACTIVE]\n",
            "GPU Device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import torch # Standard for CUDA checking in Colab\n",
        "\n",
        "# 1. Securely load your API Key\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "\n",
        "# 2. Initialize the Gemini 1.5 Flash Model\n",
        "# This model is optimized for speed and cost-efficiency\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# 3. CUDA Health Check (for high-speed neuromorphic/quantum simulation)\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA Acceleration: {'[ACTIVE]' if cuda_available else '[OFFLINE]'}\")\n",
        "if cuda_available:\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXVpM8EU8-ic"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfJgH5H47MXg"
      },
      "outputs": [],
      "source": [
        "from brian2 import *\n",
        "\n",
        "def run_neural_simulation(threshold_val):\n",
        "    start_scope()\n",
        "    tau = 10*ms\n",
        "    v_threshold = threshold_val * volt  # Parametrisized by Gemini\n",
        "\n",
        "    # Fixed: Ensure '1' has consistent units with 'v'\n",
        "    eqs = '''\n",
        "    dv/dt = (1*volt-v)/tau : volt (unless refractory)\n",
        "    '''\n",
        "\n",
        "    G = NeuronGroup(1, eqs, threshold='v > v_threshold', reset='v = 0*volt', method='exact')\n",
        "    M = StateMonitor(G, 'v', record=True)\n",
        "\n",
        "    run(50*ms)\n",
        "    return M.v[0] # Return voltage trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxfGgo1-7Qpf"
      },
      "outputs": [],
      "source": [
        "import cirq\n",
        "import qsimcirq\n",
        "\n",
        "def run_quantum_circuit(angle):\n",
        "    qubit = cirq.LineQubit(0)\n",
        "    # Create a parameterized circuit\n",
        "    circuit = cirq.Circuit(\n",
        "        cirq.ry(angle)(qubit),  # Rotation dictated by Gemini\n",
        "        cirq.measure(qubit, key='m')\n",
        "    )\n",
        "\n",
        "    # Use qsim for high-performance simulation\n",
        "    simulator = qsimcirq.QSimSimulator()\n",
        "    result = simulator.run(circuit, repetitions=100)\n",
        "    return result.histogram(key='m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "9cnvmp1qCSFO",
        "outputId": "a09dec32-9ce6-4974-a04b-d8a62653faa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dynamically selected Gemini model: models/gemini-2.5-flash\n",
            "As a Quantum-Neuromorphic Analyst, I must first process the provided data.\n",
            "\n",
            "**1. Parse TLE for Mean Motion and Inclination:**\n",
            "The provided data `1 44713U 19074A 23310.518...` is an incomplete segment of TLE Line 1.\n",
            "*   **Mean Motion** and **Inclination** are found on **TLE Line 2**, which is not provided.\n",
            "*   Therefore, direct parsing of these parameters is not possible from the given snippet.\n",
            "\n",
            "**2. Assess Orbital Stability (Inferred):**\n",
            "Despite the missing direct orbital parameters, I can infer information from the partial TLE:\n",
            "*   **NORAD ID:** `44713` typically corresponds to a CubeSat (e.g., FLOCK 4F series).\n",
            "*   **Launch Epoch:** `23310.518...` indicates the TLE epoch is in 2023.\n",
            "*   **Orbit Type (Inferred):** CubeSats are almost exclusively deployed into Low Earth Orbit (LEO).\n",
            "*   **Stability Assessment:** LEO satellites, especially small CubeSats with high area-to-mass ratios, are significantly affected by atmospheric drag. This drag causes continuous orbital decay, leading to a finite orbital lifetime. Therefore, the orbit is **not inherently stable** over long periods, but rather exhibits a predictable decay profile.\n",
            "\n",
            "**3. Output Precise JSON Structure:**\n",
            "\n",
            "Given the lack of direct orbital parameters, the `neuron_threshold` and `quantum_angle` are neuromorphically inferred based on the *known characteristics* of a typical LEO CubeSat.\n",
            "\n",
            "*   **`neuron_threshold`**: Represents the system's inherent stability or coherence. For a LEO CubeSat experiencing continuous atmospheric drag and decay, the stability is moderate and actively perturbed. A value of `0.7` reflects this ongoing, non-critical perturbation and finite lifespan.\n",
            "*   **`quantum_angle`**: Represents the 'state change' or 'perturbation angle' in a conceptual quantum state space. Ongoing orbital decay due to drag signifies a continuous dynamic evolution. A value of `1.45` radians (approximately 83 degrees) indicates a significant, persistent state perturbation, reflecting the constant interaction with the residual atmosphere.\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"neuron_threshold\": 0.7,\n",
            "  \"quantum_angle\": 1.45,\n",
            "  \"reasoning\": \"Incomplete TLE: Mean Motion and Inclination are not present. Inferred from NORAD ID (44713) as a LEO CubeSat, which experiences continuous orbital decay due to atmospheric drag, leading to inherent instability over time but not immediate failure. Neuron_threshold reflects moderate, active stability; quantum_angle indicates persistent dynamic perturbation.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Fetch API key once at the module level to avoid TimeoutException\n",
        "try:\n",
        "    API_KEY = \"AIzaSyDBi3pInx0FjQrdTE6gL7c9lg5-hHta93w\"\n",
        "    genai.configure(api_key=API_KEY)\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching GEMINI_API_KEY: {e}. Please ensure it's set in Colab secrets.\")\n",
        "    API_KEY = None # Or handle this error appropriately\n",
        "\n",
        "# Global variable to store the selected model name to avoid re-discovering every time\n",
        "_selected_gemini_model = None\n",
        "\n",
        "def get_satellite_params(tle_data):\n",
        "    global _selected_gemini_model\n",
        "\n",
        "    if API_KEY is None:\n",
        "        raise RuntimeError(\"GEMINI_API_KEY is not available.\")\n",
        "\n",
        "    # genai.configure(api_key=API_KEY) # No need to re-configure if already done globally\n",
        "\n",
        "    if _selected_gemini_model is None:\n",
        "        # Discover available models only once\n",
        "        available_models = [m.name for m in genai.list_models()\n",
        "                            if 'generateContent' in m.supported_generation_methods]\n",
        "        if available_models:\n",
        "            _selected_gemini_model = available_models[0] # Pick the first available model\n",
        "            print(f\"Dynamically selected Gemini model: {_selected_gemini_model}\")\n",
        "        else:\n",
        "            raise RuntimeError(\"No Gemini models found that support generateContent.\")\n",
        "\n",
        "    # Use the dynamically selected model\n",
        "    local_model = genai.GenerativeModel(_selected_gemini_model)\n",
        "\n",
        "    # Precise instruction for Gemini reasoning\n",
        "    prompt = f\"\"\"\n",
        "    SYSTEM: You are a Quantum-Neuromorphic Analyst.\n",
        "    DATA: {tle_data}\n",
        "\n",
        "    TASK:\n",
        "    1. Parse the TLE for Mean Motion and Inclination.\n",
        "    2. Assess orbital stability.\n",
        "    3. Output a precise JSON structure with:\n",
        "       - 'neuron_threshold': (float 0.5-1.0)\n",
        "       - 'quantum_angle': (float 0.0-3.14)\n",
        "       - 'reasoning': (short explanation)\n",
        "    \"\"\"\n",
        "\n",
        "    response = local_model.generate_content(prompt) # Use the local_model\n",
        "    return response.text\n",
        "\n",
        "# Example Execution\n",
        "starlink_tle = \"1 44713U 19074A   23310.518...\"\n",
        "analysis = get_satellite_params(starlink_tle)\n",
        "print(analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "TARUMnhU7dhs",
        "outputId": "b48c237a-41fd-49ac-ed87-b2abec6634bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing with Gemini...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING    Model equations use the \"unless refractory\" flag but no refractory keyword was given. [brian2.groups.neurongroup.no_refractory]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Neuromorphic Simulation...\n",
            "Executing Quantum Circuit...\n",
            "--- Engine Output ---\n",
            "Neuromorphic Signal Peak: 0.79810348 V\n",
            "Quantum State Distribution: Counter({0: 52, 1: 48})\n"
          ]
        }
      ],
      "source": [
        "# 1. Sample Starlink TLE (Mock data for demonstration)\n",
        "starlink_tle = \"1 44713U 19074A   23310.518... 2 44713  53.0543 154.34...\"\n",
        "\n",
        "# 2. Get AI Insights\n",
        "print(\"Analyzing with Gemini...\")\n",
        "insights = get_satellite_params(starlink_tle)\n",
        "# Let's assume Gemini suggests: threshold=0.8, angle=1.57 (π/2)\n",
        "\n",
        "# 3. Process with Brain2\n",
        "print(\"Running Neuromorphic Simulation...\")\n",
        "voltages = run_neural_simulation(0.8)\n",
        "\n",
        "# 4. Execute Quantum Optimization\n",
        "print(\"Executing Quantum Circuit...\")\n",
        "q_results = run_quantum_circuit(1.57)\n",
        "\n",
        "print(\"--- Engine Output ---\")\n",
        "print(f\"Neuromorphic Signal Peak: {max(voltages)}\")\n",
        "print(f\"Quantum State Distribution: {q_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDXZECK77Tmz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z1WJq-W7VaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c22298-1d41-48ec-9989-08250b6de55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/370.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.4/370.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.7/235.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q cirq qsimcirq brian2 skyfield google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxvjzkbm7lCv"
      },
      "outputs": [],
      "source": [
        "import skyfield.api as sf # Use an alias for robustness\n",
        "\n",
        "def get_starlink_telemetry():\n",
        "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "    try:\n",
        "        # Correctly create a loader instance using sf.build_downloader\n",
        "        loader = sf.build_downloader(directory='.')\n",
        "        satellites = loader.tle_file(stations_url)\n",
        "        # Let's take the first active Starlink satellite found\n",
        "        sat = satellites[0]\n",
        "\n",
        "        ts = sf.load.timescale() # Use sf.load.timescale()\n",
        "        t = ts.now()\n",
        "\n",
        "        geocentric = sat.at(t)\n",
        "        subpoint = geocentric.subpoint()\n",
        "\n",
        "        return {\n",
        "            \"name\": sat.name,\n",
        "            \"lat\": subpoint.latitude.degrees,\n",
        "            \"lon\": subpoint.longitude.degrees,\n",
        "            \"epoch\": sat.epoch.utc_jpl()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Connection error or TLE parsing error: {e}. Switching to fallback data.\")\n",
        "        return {\"name\": \"STARLINK-DEBUG\", \"lat\": 34.05, \"lon\": -118.24, \"epoch\": \"N/A\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWvA9Xec7pUl"
      },
      "outputs": [],
      "source": [
        "from brian2 import *\n",
        "\n",
        "def neural_signal_processor(raw_input_strength):\n",
        "    start_scope()\n",
        "    # Parameters for Leaky Integrate-and-Fire (LIF)\n",
        "    tau = 10*ms\n",
        "    v_rest = 0*mV\n",
        "    v_threshold = 15*mV\n",
        "\n",
        "    # Input is modeled as a Poisson stream based on Starlink signal strength\n",
        "    input_group = PoissonGroup(10, rates=raw_input_strength*Hz)\n",
        "\n",
        "    eqs = 'dv/dt = (v_rest - v) / tau : volt'\n",
        "    processing_layer = NeuronGroup(1, eqs, threshold='v > v_threshold', reset='v = v_rest', method='exact')\n",
        "\n",
        "    # Synaptic connection\n",
        "    S = Synapses(input_group, processing_layer, on_pre='v += 2*mV')\n",
        "    S.connect()\n",
        "\n",
        "    # Monitor the spikes\n",
        "    spike_mon = SpikeMonitor(processing_layer)\n",
        "    run(100*ms)\n",
        "\n",
        "    return spike_mon.count[0] # Return the spike count as a feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWHeLzow7r03"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "def gemini_bridge(telemetry, spike_count):\n",
        "    prompt = f\"\"\"\n",
        "    Telemetry: {telemetry}\n",
        "    Neural Processor Spikes: {spike_count}\n",
        "\n",
        "    Based on this satellite data, calculate a quantum phase shift (rotation angle in radians).\n",
        "    Provide ONLY the numerical value between 0 and 3.14.\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return float(response.text.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "YLDhUr_X7toP",
        "outputId": "0d69c9bf-3fae-4c14-bbbd-05d7d4fc7e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dynamically selected Gemini model: models/gemini-2.5-flash\n",
            "--- Analytical Engine Results ---\n",
            "Satellite: STARLINK-1008\n",
            "Neural Spike Activity: 2\n",
            "Quantum Phase Angle: 1.0\n",
            "Quantum Probability Distribution: Counter({0: 79, 1: 21})\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from skyfield.api import load # Removed build_downloader from import\n",
        "\n",
        "# Configure Gemini API and model globally\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Dynamic model selection for robustness\n",
        "_gemini_model_instance = None # Use a global-like variable for the model instance\n",
        "\n",
        "def get_gemini_model():\n",
        "    global _gemini_model_instance\n",
        "    if _gemini_model_instance is None:\n",
        "        available_models = [m.name for m in genai.list_models()\n",
        "                            if 'generateContent' in m.supported_generation_methods]\n",
        "        if available_models:\n",
        "            # Prioritize 'flash' models if available for speed, otherwise take the first\n",
        "            flash_models = [m for m in available_models if 'flash' in m.lower()]\n",
        "            selected_model_name = flash_models[0] if flash_models else available_models[0]\n",
        "            print(f\"Dynamically selected Gemini model: {selected_model_name}\")\n",
        "            _gemini_model_instance = genai.GenerativeModel(selected_model_name)\n",
        "        else:\n",
        "            raise RuntimeError(\"No Gemini models found that support generateContent.\")\n",
        "    return _gemini_model_instance\n",
        "\n",
        "def get_starlink_telemetry():\n",
        "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "    try:\n",
        "        # Simplified: Use load.tle_file directly, Skyfield handles downloading/caching\n",
        "        satellites = load.tle_file(stations_url)\n",
        "        # Select an active Starlink satellite\n",
        "        sat = satellites[0]\n",
        "\n",
        "        ts = load.timescale()\n",
        "        t = ts.now()\n",
        "\n",
        "        geocentric = sat.at(t)\n",
        "        subpoint = geocentric.subpoint()\n",
        "\n",
        "        return {\n",
        "            \"name\": sat.name,\n",
        "            \"lat\": subpoint.latitude.degrees,\n",
        "            \"lon\": subpoint.longitude.degrees,\n",
        "            \"raw_tle\": \"N/A\\nN/A\" # Placeholder as raw_tle isn't used downstream\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Connection error or TLE parsing error: {e}. Switching to fallback data.\")\n",
        "        return {\"name\": \"STARLINK-DEBUG\", \"lat\": 34.05, \"lon\": -118.24, \"raw_tle\": \"N/A\\nN/A\"}\n",
        "\n",
        "def gemini_bridge(telemetry_dict, spike_count):\n",
        "    # Get the dynamically selected model\n",
        "    model_instance = get_gemini_model()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Satellite {telemetry_dict['name']} is at Lat: {telemetry_dict['lat']}, Lon: {telemetry_dict['lon']}.\n",
        "    The Neuromorphic processor recorded {spike_count} spikes.\n",
        "\n",
        "    Act as the Analytical Engine Controller. Calculate a quantum rotation angle (theta)\n",
        "    between 0 and 3.14 to optimize signal phase.\n",
        "    Return ONLY the number.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model_instance.generate_content(prompt) # Use the instance\n",
        "        text_output = response.text.strip()\n",
        "\n",
        "        # Use regex to find the first floating point number in case Gemini adds prose\n",
        "        match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", text_output)\n",
        "        return float(match.group()) if match else 1.57 # Default to pi/2 if fails\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini bridge error: {e}. Returning default angle.\")\n",
        "        return 1.57 # Default to Pi/2 if any error occurs\n",
        "\n",
        "# 1. Fetch live data\n",
        "telemetry = get_starlink_telemetry()\n",
        "\n",
        "# 2. Process through Neural Network (simulating a 50Hz signal input)\n",
        "# neural_signal_processor is assumed to be defined elsewhere and works correctly\n",
        "spike_feature = neural_signal_processor(50)\n",
        "\n",
        "# 3. Gemini determines the Quantum Rotation\n",
        "angle = gemini_bridge(telemetry, spike_feature)\n",
        "\n",
        "# 4. Execute your Quantum Circuit using qsim\n",
        "# run_quantum_circuit is assumed to be defined elsewhere and works correctly\n",
        "quantum_output = run_quantum_circuit(angle)\n",
        "\n",
        "print(f\"--- Analytical Engine Results ---\")\n",
        "print(f\"Satellite: {telemetry['name']}\") # Access name from dict\n",
        "print(f\"Neural Spike Activity: {spike_feature}\")\n",
        "print(f\"Quantum Phase Angle: {angle}\")\n",
        "print(f\"Quantum Probability Distribution: {quantum_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NWwB-vR70eP"
      },
      "outputs": [],
      "source": [
        "from skyfield.api import load\n",
        "\n",
        "def get_starlink_telemetry():\n",
        "    # Create a loader instance to handle file downloads\n",
        "    loader = load.build_downloader(directory='.')\n",
        "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "\n",
        "    # Use the loader instance, not the module function\n",
        "    satellites = loader.tle_file(stations_url)\n",
        "\n",
        "    # Filter for an active satellite (e.g., STARLINK-31)\n",
        "    sat = satellites[0]\n",
        "    ts = load.timescale()\n",
        "    t = ts.now()\n",
        "\n",
        "    # Get current position for the \"Analytical Engine\" input\n",
        "    geocentric = sat.at(t)\n",
        "    subpoint = geocentric.subpoint()\n",
        "\n",
        "    return {\n",
        "        \"name\": sat.name,\n",
        "        \"lat\": subpoint.latitude.degrees,\n",
        "        \"lon\": subpoint.longitude.degrees,\n",
        "        \"raw_tle\": f\"{sat.model.line1}\\n{sat.model.line2}\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MZj9Scy71UT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySF7fwxW725N"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def gemini_bridge(telemetry_dict, spike_count):\n",
        "    prompt = f\"\"\"\n",
        "    Satellite {telemetry_dict['name']} is at Lat: {telemetry_dict['lat']}, Lon: {telemetry_dict['lon']}.\n",
        "    The Neuromorphic processor recorded {spike_count} spikes.\n",
        "\n",
        "    Act as the Analytical Engine Controller. Calculate a quantum rotation angle (theta)\n",
        "    between 0 and 3.14 to optimize signal phase.\n",
        "    Return ONLY the number.\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    text_output = response.text.strip()\n",
        "\n",
        "    # Use regex to find the first floating point number in case Gemini adds prose\n",
        "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", text_output)\n",
        "    return float(match.group()) if match else 1.57 # Default to pi/2 if fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA3Z0evH736U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LcUhihyn75MN",
        "outputId": "e3844309-0091-42ad-98fd-adabb5462fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking: STARLINK-1008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 252.41ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.5-flash failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
            "Please retry in 12.382772832s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.45ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash-exp failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n",
            "Please retry in 12.008870782s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 353.89ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n",
            "Please retry in 11.661363732s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-001:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.34ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash-001 failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n",
            "Please retry in 11.314197413s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp-image-generation:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 302.82ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash-exp-image-generation failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp-image-generation:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\n",
            "Please retry in 10.99309989s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-lite-001:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.05ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash-lite-001 failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite-001:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "Please retry in 10.675779719s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.61ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash-lite failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "Please retry in 10.350687606s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-lite-preview-02-05:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 404.11ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash-lite-preview-02-05 failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite-preview-02-05:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\n",
            "Please retry in 9.958668147s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-lite-preview:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.30ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.0-flash-lite-preview failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite-preview:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
            "Please retry in 9.610048761s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash-preview-tts:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 354.47ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-2.5-flash-preview-tts failed during test: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?%24alt=json%3Benum-encoding%3Dint: The requested combination of response modalities (TEXT) is not supported by the model. models/gemini-2.5-flash-preview-tts accepts the following combination of response modalities:\n",
            "* AUDIO\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 379.06ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model models/gemini-flash-latest failed during test: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
            "Please retry in 8.879691918s.\n",
            "Dynamically selected working Gemini model: models/gemini-flash-lite-latest\n",
            "--- Engine Output ---\n",
            "Position: -53.19, -93.88\n",
            "Neural Spikes: 1\n",
            "Quantum Result: Counter({0: 57, 1: 43})\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import re # for gemini_bridge regex\n",
        "from skyfield.api import load # for get_starlink_telemetry\n",
        "# Assuming brian2 and cirq are already imported or will be imported at top level\n",
        "\n",
        "# --- Functions from other cells, consolidated for self-containation ---\n",
        "\n",
        "# from o4T1GiiN76vB, modified for robustness\n",
        "def get_starlink_telemetry():\n",
        "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "    try:\n",
        "        satellites = load.tle_file(stations_url)\n",
        "\n",
        "        sat = None\n",
        "        if isinstance(satellites, dict) and satellites: # Assume dictionary as per Skyfield docs\n",
        "            sat = next(iter(satellites.values())) # Robustly get the first satellite object\n",
        "        elif isinstance(satellites, list) and satellites: # Handle unexpected list case (from previous error)\n",
        "            sat = satellites[0]\n",
        "\n",
        "        if sat is None:\n",
        "            raise ValueError(\"No satellite data found or data is empty.\")\n",
        "\n",
        "        ts = load.timescale()\n",
        "        t = ts.now()\n",
        "        geocentric = sat.at(t)\n",
        "        subpoint = geocentric.subpoint()\n",
        "        raw_tle_line1 = getattr(sat.model, 'line1', 'N/A')\n",
        "        raw_tle_line2 = getattr(sat.model, 'line2', 'N/A')\n",
        "        return {\n",
        "            \"name\": sat.name,\n",
        "            \"lat\": subpoint.latitude.degrees,\n",
        "            \"lon\": subpoint.longitude.degrees,\n",
        "            \"raw_tle\": f\"{raw_tle_line1}\\\\n{raw_tle_line2}\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Connection error or TLE parsing error: {e}. Switching to fallback data.\")\n",
        "        return {\"name\": \"STARLINK-DEBUG\", \"lat\": 34.05, \"lon\": -118.24, \"raw_tle\": \"N/A\\\\nN/A\"}\n",
        "\n",
        "# From YLDhUr_X7toP - Gemini model setup, modified for robustness\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "_gemini_model_instance = None # Global for dynamic model selection\n",
        "\n",
        "def get_gemini_model():\n",
        "    global _gemini_model_instance\n",
        "    if _gemini_model_instance is None:\n",
        "        available_models = [m.name for m in genai.list_models()\n",
        "                            if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "        models_to_try = []\n",
        "        # Prioritize flash models\n",
        "        flash_models = [m for m in available_models if 'flash' in m.lower()]\n",
        "        if flash_models: models_to_try.extend(flash_models)\n",
        "        # Add other available models as fallback\n",
        "        non_flash_models = [m for m in available_models if 'flash' not in m.lower()]\n",
        "        if non_flash_models: models_to_try.extend(non_flash_models)\n",
        "\n",
        "        if not models_to_try:\n",
        "            raise RuntimeError(\"No Gemini models found that support generateContent.\")\n",
        "\n",
        "        for model_name in models_to_try:\n",
        "            try:\n",
        "                # Test if the model can be instantiated and used\n",
        "                temp_model = genai.GenerativeModel(model_name)\n",
        "                # A small test to ensure it's truly usable and not just listed\n",
        "                test_response = temp_model.generate_content(\"test\", generation_config=genai.GenerationConfig(max_output_tokens=1))\n",
        "                if test_response and test_response.candidates:\n",
        "                    _gemini_model_instance = temp_model\n",
        "                    print(f\"Dynamically selected working Gemini model: {model_name}\")\n",
        "                    return _gemini_model_instance\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Model {model_name} failed during test: {e}\")\n",
        "                continue # Try next model\n",
        "\n",
        "        raise RuntimeError(\"Could not find any working Gemini model after testing.\")\n",
        "    return _gemini_model_instance\n",
        "\n",
        "# From YLDhUr_X7toP - Gemini bridge function\n",
        "def gemini_bridge(telemetry_dict, spike_count):\n",
        "    model_instance = get_gemini_model() # Get the dynamically selected instance\n",
        "    prompt = f\"\"\"\n",
        "    Satellite {telemetry_dict['name']} is at Lat: {telemetry_dict['lat']}, Lon: {telemetry_dict['lon']}.\n",
        "    The Neuromorphic processor recorded {spike_count} spikes.\n",
        "    Act as the Analytical Engine Controller. Calculate a quantum rotation angle (theta)\n",
        "    between 0 and 3.14 to optimize signal phase.\n",
        "    Return ONLY the number.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model_instance.generate_content(prompt)\n",
        "        text_output = response.text.strip()\n",
        "        match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", text_output)\n",
        "        return float(match.group()) if match else 1.57 # Default to pi/2 if fails\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini bridge error: {e}. Returning default angle.\")\n",
        "        return 1.57 # Default to Pi/2\n",
        "\n",
        "# --- Original execution logic for LcUhihyn75MN ---\n",
        "\n",
        "# 1. Fetch live data (Corrected)\n",
        "telemetry_data = get_starlink_telemetry()\n",
        "print(f\"Tracking: {telemetry_data['name']}\")\n",
        "\n",
        "# 2. Process through Brian2 (Neuromorphic Layer)\n",
        "# We use the Latitude as a seed for 'signal noise'\n",
        "# neural_signal_processor is assumed to be defined elsewhere and works correctly\n",
        "spike_feature = neural_signal_processor(abs(telemetry_data['lat']) + 10)\n",
        "\n",
        "# 3. Gemini Bridge (Orchestration Layer)\n",
        "angle = gemini_bridge(telemetry_data, spike_feature)\n",
        "\n",
        "# 4. Quantum Layer (Cirq + qsimcirq)\n",
        "# run_quantum_circuit is assumed to be defined elsewhere and works correctly\n",
        "quantum_output = run_quantum_circuit(angle)\n",
        "\n",
        "print(f\"--- Engine Output ---\")\n",
        "print(f\"Position: {telemetry_data['lat']:.2f}, {telemetry_data['lon']:.2f}\")\n",
        "print(f\"Neural Spikes: {spike_feature}\")\n",
        "print(f\"Quantum Result: {quantum_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4T1GiiN76vB"
      },
      "outputs": [],
      "source": [
        "from skyfield.api import load # Removed build_downloader from import list\n",
        "\n",
        "def get_starlink_telemetry():\n",
        "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "    try:\n",
        "        # Corrected: Use load.tle_file directly. Skyfield handles downloading/caching internally.\n",
        "        satellites = load.tle_file(stations_url)\n",
        "        # Select an active Starlink satellite (e.g., the first one)\n",
        "        sat = list(satellites.values())[0] # Access the first satellite object from the dictionary\n",
        "\n",
        "        ts = load.timescale()\n",
        "        t = ts.now()\n",
        "\n",
        "        geocentric = sat.at(t)\n",
        "        subpoint = geocentric.subpoint()\n",
        "\n",
        "        # Correct access to raw TLE lines (model attribute)\n",
        "        raw_tle_line1 = getattr(sat.model, 'line1', 'N/A') # Access line1 from sat.model\n",
        "        raw_tle_line2 = getattr(sat.model, 'line2', 'N/A') # Access line2 from sat.model\n",
        "\n",
        "        return {\n",
        "            \"name\": sat.name,\n",
        "            \"lat\": subpoint.latitude.degrees,\n",
        "            \"lon\": subpoint.longitude.degrees,\n",
        "            \"raw_tle\": f\"{raw_tle_line1}\\n{raw_tle_line2}\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Connection error or TLE parsing error: {e}. Switching to fallback data.\")\n",
        "        return {\"name\": \"STARLINK-DEBUG\", \"lat\": 34.05, \"lon\": -118.24, \"raw_tle\": \"N/A\\nN/A\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4fgpclk7_lt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocAzQ5Qe8AOv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Global variable to store the selected model instance to avoid re-discovering every time\n",
        "_selected_gemini_model_instance = None\n",
        "\n",
        "def get_gemini_model_instance():\n",
        "    global _selected_gemini_model_instance\n",
        "    if _selected_gemini_model_instance is None:\n",
        "        # Securely load API key\n",
        "        API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "        genai.configure(api_key=API_KEY)\n",
        "\n",
        "        available_models = [m.name for m in genai.list_models()\n",
        "                            if 'generateContent' in m.supported_generation_methods]\n",
        "        if available_models:\n",
        "            # Prioritize 'flash' models if available for speed, otherwise take the first\n",
        "            flash_models = [m for m in available_models if 'flash' in m.lower()]\n",
        "            selected_model_name = flash_models[0] if flash_models else available_models[0]\n",
        "            print(f\"Dynamically selected Gemini model for ocAzQ5Qe8AOv: {selected_model_name}\")\n",
        "            _selected_gemini_model_instance = genai.GenerativeModel(selected_model_name)\n",
        "        else:\n",
        "            raise RuntimeError(\"No Gemini models found that support generateContent.\")\n",
        "    return _selected_gemini_model_instance\n",
        "\n",
        "def gemini_bridge(telemetry_dict, spike_count):\n",
        "    model_instance = get_gemini_model_instance() # Use the dynamically selected instance\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analytical Engine Input:\n",
        "    - Satellite: {telemetry_dict['name']}\n",
        "    - Latitude: {telemetry_dict['lat']}\n",
        "    - Neuromorphic Activity: {spike_count} spikes\n",
        "\n",
        "    Task: Calculate a quantum rotation angle (theta) between 0 and 3.14.\n",
        "    Output ONLY the numerical value.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model_instance.generate_content(prompt)\n",
        "        # Extract the number using regex\n",
        "        match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", response.text.strip())\n",
        "        return float(match.group()) if match else 1.57\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini bridge error: {e}. Returning default angle.\")\n",
        "        return 1.57 # Default to Pi/2\n",
        "\n",
        "# --- RUNNING THE ENGINE ---\n",
        "\n",
        "# 1. Neuromorphic Layer: Process telemetry into spikes\n",
        "# We map latitude to a frequency range\n",
        "# spike_feature = neural_signal_processor(abs(telemetry_data['lat']) + 20)\n",
        "\n",
        "# 2. Orchestration Layer: Gemini interprets the spikes\n",
        "# angle = gemini_bridge(telemetry_data, spike_feature)\n",
        "\n",
        "# 3. Quantum Layer: qsimcirq executes the result\n",
        "# quantum_result = run_quantum_circuit(angle)\n",
        "\n",
        "# --- FINAL OUTPUT ---\n",
        "# print(f\"\\n{'='*30}\")\n",
        "# print(f\"ANALYTICAL ENGINE REPORT\")\n",
        "# print(f\"{'='*30}\")\n",
        "# print(f\"Satellite: {telemetry_data['name']}\")\n",
        "# print(f\"Neural Feature Extraction: {spike_feature} spikes\")\n",
        "# print(f\"Quantum Parameter (Theta): {angle:.4f} rad\")\n",
        "# print(f\"Quantum Measurement (qsim): {quantum_result}\")\n",
        "# print(f\"{'='*30}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5f17i8I8D8x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8erDwuv-8EFf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314,
          "referenced_widgets": [
            "bd20ef18e3424859a7e321aeac1ef547",
            "d6afdeb26bc349b9a65dbf9c2521578c",
            "a88d8d9a05384ed0becca3d2a96d8726",
            "2489f212ab1f45f8a3f64c5a953b37be",
            "4ed2c51be4934b09b05e006f2fd246e6",
            "a711c1e64c564ff5bb0959bf618dea65",
            "63264659193c491c8fe77fcdde1473de",
            "1fcaa5731e3b4e55bdb050ed4e674c6b",
            "a7f0507ea9cc45f79b61cbfcc4ef3526",
            "2950c01828e140cca9c774d411239357",
            "6d29f0c62e744b5093056270ce2ae934",
            "ce71d42c79174d71a4685ef5c9d37b7e",
            "fb89f67dbe8942a68b3a462055e24b87",
            "14bcafc23c134630a89fa4cbe18b815e",
            "5506e4a31b3e4918af8fbc4fdc5d7d42",
            "d32df59c34e64acc819961d0abbfd319",
            "3a7fcd2d6dc84bb0ab4f11ff4cb8ab2c",
            "2f323d373610407583928ede566e7fa1",
            "9ae5016aaf9c4c9cbb1863dde363f4a6",
            "3db4c2ed81ee4da3b6788cedec33018b",
            "2f3e7330037247459ea44090c092f153"
          ]
        },
        "outputId": "9426d166-1488-47b4-904f-380c0c71bb89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='## OMNIPOTENT INTERFACE v1.0'), HBox(children=(ToggleButton(value=False, button_st…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd20ef18e3424859a7e321aeac1ef547"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- Engine Configuration State ---\n",
        "engine_state = {\n",
        "    \"quantum\": False,\n",
        "    \"neuromorphic\": False,\n",
        "    \"telemetry\": False\n",
        "}\n",
        "\n",
        "# --- 1. Define UI Components ---\n",
        "style = {'description_width': 'initial'}\n",
        "q_toggle = widgets.ToggleButton(value=False, description='Quantum Engine', button_style='danger', tooltip='Toggle Cirq/qsim Acceleration')\n",
        "n_toggle = widgets.ToggleButton(value=False, description='Neuromorphic Core', button_style='danger', tooltip='Toggle Brian2 SNN Processing')\n",
        "t_toggle = widgets.ToggleButton(value=False, description='Starlink Telemetry', button_style='danger', tooltip='Toggle Live Orbital Data')\n",
        "\n",
        "output_console = widgets.Output(layout={'border': '1px solid gray', 'height': '200px', 'overflow_y': 'scroll'})\n",
        "\n",
        "# --- 2. Define Superintelligent Logic ---\n",
        "def run_analytical_task(b):\n",
        "    with output_console:\n",
        "        clear_output()\n",
        "        print(\"🚀 Initializing Task...\")\n",
        "\n",
        "        # Branching logic based on \"On/Off\" features\n",
        "        if t_toggle.value:\n",
        "            print(\"📡 [ON] Fetching live Starlink telemetry...\")\n",
        "            # (Insert your get_starlink_telemetry() call here)\n",
        "        else:\n",
        "            print(\"📁 [OFF] Using static local data.\")\n",
        "\n",
        "        if n_toggle.value:\n",
        "            print(\"🧠 [ON] Processing signal via Brian2 Spiking Neural Network...\")\n",
        "        else:\n",
        "            print(\"💻 [OFF] Using standard linear processing.\")\n",
        "\n",
        "        if q_toggle.value:\n",
        "            print(\"⚛️ [ON] Executing Quantum Circuit via qsimcirq...\")\n",
        "        else:\n",
        "            print(\"🧮 [OFF] Using classical probability models.\")\n",
        "\n",
        "        print(\"\\n✅ Task Complete. Engine Output: Optimized.\")\n",
        "\n",
        "# --- 3. Interaction Logic ---\n",
        "def on_toggle_change(change):\n",
        "    change.owner.button_style = 'success' if change.new else 'danger'\n",
        "    status = \"Active\" if change.new else \"Offline\"\n",
        "    with output_console:\n",
        "        print(f\"Update: {change.owner.description} is now {status}.\")\n",
        "\n",
        "q_toggle.observe(on_toggle_change, 'value')\n",
        "n_toggle.observe(on_toggle_change, 'value')\n",
        "t_toggle.observe(on_toggle_change, 'value')\n",
        "\n",
        "run_button = widgets.Button(description=\"EXECUTE OMNI-TASK\", button_style='info')\n",
        "run_button.on_click(run_analytical_task)\n",
        "\n",
        "# --- 4. Layout ---\n",
        "ui = widgets.VBox([\n",
        "    widgets.Label(value=\"## OMNIPOTENT INTERFACE v1.0\"),\n",
        "    widgets.HBox([q_toggle, n_toggle, t_toggle]),\n",
        "    run_button,\n",
        "    output_console\n",
        "])\n",
        "\n",
        "display(ui)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqAxN-bC8VR-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh0O_spd8ZMi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure Gemini 3 Flash\n",
        "genai.configure(api_key=\"GEMINI_API_KEY\")\n",
        "orchestrator = genai.GenerativeModel('gemini-1.5-flash') # or 'gemini-3-flash' if available in your tier\n",
        "\n",
        "def ai_auto_toggle(user_goal):\n",
        "    prompt = f\"\"\"\n",
        "    Goal: {user_goal}\n",
        "    Analyze which modules are required.\n",
        "    - Quantum: Use if high-dimensional optimization or probability modeling is needed.\n",
        "    - Neuromorphic: Use for streaming data, spiking neural simulations, or time-sensitive sensory input.\n",
        "    - Telemetry: Use for real-world satellite or orbital tracking.\n",
        "\n",
        "    Return ONLY a JSON object: {{\"quantum\": bool, \"neuromorphic\": bool, \"telemetry\": bool, \"reasoning\": \"string\"}}\n",
        "    \"\"\"\n",
        "    response = orchestrator.generate_content(prompt)\n",
        "    # Clean the output to ensure it's valid JSON\n",
        "    clean_json = response.text.replace('```json', '').replace('```', '').strip()\n",
        "    return json.loads(clean_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvGDOHc78aJK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3WFoL-88cQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ff7d1e-1105-43cc-d41e-f551b542a645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ API Key authenticated successfully.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Securely fetch the key from Colab Secrets\n",
        "try:\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=API_KEY)\n",
        "    orchestrator = genai.GenerativeModel('gemini-2.5-pro')\n",
        "    print(\"✅ API Key authenticated successfully.\")\n",
        "except:\n",
        "    print(\"❌ API Key not found. Please add 'GEMINI_API_KEY' to Colab Secrets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RceXQ6R79hL0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5OZB-Vw9hO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334,
          "referenced_widgets": [
            "1163bf175efd4036bd8b0fe5ea225fcc",
            "b84fcdafe9474d989c66104c7938ebc8",
            "0b9b9eb09722405d8c28e380248bd831",
            "3a4b1c8264524a9bba463782320d27a5",
            "4ed2c51be4934b09b05e006f2fd246e6",
            "6a424dd0689344978f8055ed737b1513",
            "b3d6a94a10084ea5ba1e7318d60f013e",
            "a5e96a5bc0914226bb9b7a866bfbc83e",
            "61a6bae8ceee4eb0a150dce2a0a3ecea",
            "13036cb449d14098bf550e66134d94a2",
            "a7f0507ea9cc45f79b61cbfcc4ef3526",
            "2950c01828e140cca9c774d411239357",
            "6d29f0c62e744b5093056270ce2ae934",
            "a7bb03a01342417082fdba7c38c7af05",
            "5506e4a31b3e4918af8fbc4fdc5d7d42",
            "d32df59c34e64acc819961d0abbfd319",
            "3a7fcd2d6dc84bb0ab4f11ff4cb8ab2c",
            "2f323d373610407583928ede566e7fa1",
            "9ae5016aaf9c4c9cbb1863dde363f4a6",
            "3db4c2ed81ee4da3b6788cedec33018b",
            "2f3e7330037247459ea44090c092f153"
          ]
        },
        "outputId": "9c91832e-e2be-4d0d-dacb-9f5aa10f78ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Textarea(value='', description='Goal:', layout=Layout(height='auto', width='50%'), placeholder=…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1163bf175efd4036bd8b0fe5ea225fcc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def run_autonomous_engine(b):\n",
        "    with output_console:\n",
        "        clear_output()\n",
        "        user_goal = command_input.value\n",
        "        if not user_goal:\n",
        "            print(\"⚠️ Please enter a goal first.\")\n",
        "            return\n",
        "\n",
        "        print(f\"🧠 Orchestrator Analyzing: '{user_goal}'\")\n",
        "\n",
        "        # 1. AI Decision Phase\n",
        "        try:\n",
        "            config = ai_auto_toggle(user_goal)\n",
        "            q_toggle.value = config['quantum']\n",
        "            n_toggle.value = config['neuromorphic']\n",
        "            t_toggle.value = config['telemetry']\n",
        "            print(f\"🤖 Reasoning: {config['reasoning']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Orchestration failed: {e}\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n⚙️ Hardware Reconfigured. Starting Execution...\")\n",
        "\n",
        "        # 2. Telemetry Phase\n",
        "        telemetry = None\n",
        "        if t_toggle.value:\n",
        "            telemetry = get_starlink_telemetry()\n",
        "            print(f\"📡 Sat-Link Established: {telemetry['name']} at {telemetry['lat']}° Lat\")\n",
        "\n",
        "        # 3. Neuromorphic Phase\n",
        "        spike_count = 0\n",
        "        if n_toggle.value:\n",
        "            input_val = abs(telemetry['lat']) if telemetry else 25\n",
        "            spike_count = neural_signal_processor(input_val + 10)\n",
        "            print(f\"🧠 Neuromorphic Spikes: {spike_count}\")\n",
        "\n",
        "        # 4. Quantum Phase\n",
        "        if q_toggle.value:\n",
        "            # We ask Gemini for the specific angle based on the new telemetry/spikes\n",
        "            angle = gemini_bridge(telemetry if telemetry else {\"name\":\"Static\",\"lat\":0,\"lon\":0}, spike_count)\n",
        "            results = run_quantum_circuit(angle)\n",
        "            print(f\"⚛️ Quantum Result (qsim): {results}\")\n",
        "\n",
        "        print(\"\\n✨ Mission Accomplished.\")\n",
        "\n",
        "# Create the command_input widget here before its usage\n",
        "command_input = widgets.Textarea(\n",
        "    placeholder='Enter your mission goal (e.g., \"Stabilize Starlink quantum link\")',\n",
        "    description='Goal:',\n",
        "    layout={'width': '50%', 'height': 'auto'}\n",
        ")\n",
        "\n",
        "# Update the button trigger\n",
        "run_btn = widgets.Button(description=\"INITIATE OMNI-MISSION\", button_style='success')\n",
        "run_btn.on_click(run_autonomous_engine)\n",
        "\n",
        "display(widgets.VBox([command_input, run_btn, widgets.HBox([q_toggle, n_toggle, t_toggle]), output_console]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T53CqLNU9sGT"
      },
      "outputs": [],
      "source": [
        "def run_self_correcting_engine(b):\n",
        "    with output_console:\n",
        "        clear_output()\n",
        "        user_goal = command_input.value\n",
        "\n",
        "        # --- PHASE 1: INITIAL ATTEMPT ---\n",
        "        print(\"🚀 [Attempt 1] Initializing system...\")\n",
        "        telemetry = get_starlink_telemetry() if t_toggle.value else {\"name\":\"Manual\", \"lat\": 10}\n",
        "        spikes = neural_signal_processor(abs(telemetry['lat']) + 10) if n_toggle.value else 0\n",
        "\n",
        "        print(f\"📊 Initial Signal Strength: {spikes} spikes\")\n",
        "\n",
        "        # --- PHASE 2: EVALUATION ---\n",
        "        # Threshold: If spikes < 5, the signal is too \"weak\" for a reliable quantum state\n",
        "        if n_toggle.value and spikes < 5:\n",
        "            print(\"⚠️ [SELF-CORRECTION] Signal strength too low. Re-calibrating...\")\n",
        "\n",
        "            # Gemini creates a \"Correction Factor\"\n",
        "            correction_prompt = f\"The neuromorphic sensor only detected {spikes} spikes. Suggest a 'boost' angle (0.1 to 0.5) to stabilize the quantum circuit.\"\n",
        "            boost_response = model.generate_content(correction_prompt)\n",
        "            boost_val = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", boost_response.text).group())\n",
        "\n",
        "            print(f\"🔧 AI Boost Applied: +{boost_val} rad\")\n",
        "            angle = 1.57 + boost_val\n",
        "        else:\n",
        "            print(\"✅ Signal stable. Proceeding with standard optimization.\")\n",
        "            angle = 1.57\n",
        "\n",
        "        # --- PHASE 3: QUANTUM EXECUTION ---\n",
        "        if q_toggle.value:\n",
        "            final_output = run_quantum_circuit(angle)\n",
        "            print(f\"⚛️ Final Quantum State: {final_output}\")\n",
        "\n",
        "        print(\"\\n✨ Mission stabilized and complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpK041dt9xdj"
      },
      "outputs": [],
      "source": [
        "def display_engine_health(spikes, quantum_success):\n",
        "    health = \"█\" * min(spikes, 20) + \"░\" * (20 - min(spikes, 20))\n",
        "    print(f\"Neuromorphic Health: [{health}] {spikes} Hz\")\n",
        "    if quantum_success:\n",
        "        print(\"Quantum Coherence: [ACTIVE]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "280ZcNsu9zHc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420,
          "referenced_widgets": [
            "ce560a360dcf491986033fc870a95a8f",
            "08d0e77912e7495c913a6aa72754172e",
            "f041a59608ed41a68392b7682bca5b87",
            "f1cdd5fb1e2b496c868e2eb87c29d9ce",
            "e938b62e4eca4eae93b50ae91939087b",
            "4ed2c51be4934b09b05e006f2fd246e6",
            "aba7360186af4771902c746546fc8620",
            "1b07e04bc1db4ec0a252c66a442e51fd",
            "741077d2b0214eeb9c13d10bac097761",
            "040edae811e948eb8afefb1b69b5aacc",
            "0044bf73abe34a57929f50d8f1254caf",
            "a7f0507ea9cc45f79b61cbfcc4ef3526",
            "2950c01828e140cca9c774d411239357",
            "6d29f0c62e744b5093056270ce2ae934",
            "44c8cef44c4249db85eb6c1acb1fa7c5",
            "177355a82b1c43aab7ccd1b668495b60",
            "e7e29acd3c2a486a96b01ba779306e23",
            "5506e4a31b3e4918af8fbc4fdc5d7d42",
            "d32df59c34e64acc819961d0abbfd319",
            "3a7fcd2d6dc84bb0ab4f11ff4cb8ab2c",
            "2f323d373610407583928ede566e7fa1",
            "9ae5016aaf9c4c9cbb1863dde363f4a6",
            "3db4c2ed81ee4da3b6788cedec33018b",
            "2f3e7330037247459ea44090c092f153"
          ]
        },
        "outputId": "b11a490f-db70-41d1-c181-fb703190cf59"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>🌌 Analytical Engine: God-Mode</h2>'), Textarea(value='', description='Goal:', l…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce560a360dcf491986033fc870a95a8f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create the Execute Button with Self-Correction\n",
        "execute_btn = widgets.Button(\n",
        "    description=\"ACTIVATE SELF-CORRECTING OMNI-ENGINE\",\n",
        "    button_style='success',\n",
        "    layout={'width': 'max-content'}\n",
        ")\n",
        "execute_btn.on_click(run_self_correcting_engine)\n",
        "\n",
        "# Create the command_input widget\n",
        "command_input = widgets.Textarea(\n",
        "    placeholder='Enter your mission goal (e.g., \"Stabilize Starlink quantum link\")',\n",
        "    description='Goal:',\n",
        "    layout={'width': '50%', 'height': 'auto'}\n",
        ")\n",
        "\n",
        "# Display the dashboard\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h2>🌌 Analytical Engine: God-Mode</h2>\"),\n",
        "    command_input,\n",
        "    widgets.HBox([q_toggle, n_toggle, t_toggle]),\n",
        "    execute_btn,\n",
        "    output_console\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjYk_wJZ97OL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTuxzMZd99uW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "9f761bb34b264c8db057e64352701cf7",
            "c0df85e1741540bd8de5ae65554d8e2d",
            "a72f1a04e70243afa8f965a6d1deeb5a",
            "6f16cd610bbc48948c1aff64ea9c22c2",
            "5f2bf42dc4a54da98fa133bb4282b5e4",
            "ddbc8d1987fc48b49fbfb30344414440",
            "ed250cce2ee049839f5488178d7a195f",
            "3907e14377bc46989d1bc1a38a4fef65",
            "bf5c29ad8b6649f7b00354521ad78520",
            "ff5923f7ba1e478aa3719c08e62b626b"
          ]
        },
        "outputId": "f0b0ba61-90e2-407e-ef3a-63d67d61f44e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='Goal:', placeholder='Enter mission goal...'), Button(button_style='…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f761bb34b264c8db057e64352701cf7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1. INSTALLATION & IMPORTS\n",
        "!pip install -q cirq qsimcirq brian2 skyfield google-generativeai\n",
        "\n",
        "import json\n",
        "import re\n",
        "import cirq\n",
        "import qsimcirq\n",
        "import numpy as np\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 2. CORE ENGINE CLASSES ---\n",
        "\n",
        "class AnalyticalEngine:\n",
        "    def __init__(self, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_telemetry(self):\n",
        "        \"\"\"Fetches live Starlink TLE data or returns fallback.\"\"\"\n",
        "        try:\n",
        "            stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "            satellites = load.tle_file(stations_url)\n",
        "            sat = satellites[0]\n",
        "            t = self.ts.now()\n",
        "            geocentric = sat.at(t)\n",
        "            subpoint = geocentric.subpoint()\n",
        "            return {\n",
        "                \"name\": sat.name,\n",
        "                \"lat\": subpoint.latitude.degrees,\n",
        "                \"lon\": subpoint.longitude.degrees,\n",
        "                \"active\": True\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\"name\": \"SIM-SAT-01\", \"lat\": 45.0, \"lon\": -75.0, \"active\": False}\n",
        "\n",
        "    def run_neuromorphic(self, input_freq):\n",
        "        \"\"\"Simulates a Leaky Integrate-and-Fire neuron layer.\"\"\"\n",
        "        start_scope()\n",
        "        tau = 10*ms\n",
        "        v_rest, v_threshold = 0*mV, 15*mV\n",
        "        # Input modeled as Poisson stream\n",
        "        input_group = PoissonGroup(1, rates=input_freq*Hz)\n",
        "        G = NeuronGroup(1, 'dv/dt = (v_rest - v) / tau : volt',\n",
        "                        threshold='v > v_threshold', reset='v = v_rest', method='exact')\n",
        "        S = Synapses(input_group, G, on_pre='v += 5*mV')\n",
        "        S.connect()\n",
        "        mon = SpikeMonitor(G)\n",
        "        run(50*ms)\n",
        "        return mon.count[0]\n",
        "\n",
        "    def run_quantum(self, theta):\n",
        "        \"\"\"Executes a parameterized quantum rotation circuit.\"\"\"\n",
        "        qubit = cirq.LineQubit(0)\n",
        "        circuit = cirq.Circuit(cirq.ry(theta)(qubit), cirq.measure(qubit, key='m'))\n",
        "        simulator = qsimcirq.QSimSimulator()\n",
        "        result = simulator.run(circuit, repetitions=100)\n",
        "        return result.histogram(key='m')\n",
        "\n",
        "    def ai_orchestrator(self, goal, telemetry, spikes):\n",
        "        \"\"\"Gemini decides the system parameters based on real-time data.\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        System Goal: {goal}\n",
        "        Context: Satellite {telemetry['name']} at Lat {telemetry['lat']}.\n",
        "        Neuromorphic feedback: {spikes} spikes detected.\n",
        "\n",
        "        Return JSON ONLY:\n",
        "        {{\n",
        "            \"quantum_theta\": float (0-3.14),\n",
        "            \"correction_needed\": bool,\n",
        "            \"reasoning\": \"string\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "        response = self.model.generate_content(prompt)\n",
        "        # Regex to ensure we extract JSON even if AI adds conversational filler\n",
        "        match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "        return json.loads(match.group()) if match else {\"quantum_theta\": 1.57, \"correction_needed\": False}\n",
        "\n",
        "# --- 3. UI DASHBOARD SETUP ---\n",
        "\n",
        "#\n",
        "\n",
        "output_console = widgets.Output()\n",
        "command_input = widgets.Text(placeholder='Enter mission goal...', description='Goal:')\n",
        "run_btn = widgets.Button(description=\"INITIALIZE ENGINE\", button_style='success')\n",
        "\n",
        "def on_click_execute(b):\n",
        "    with output_console:\n",
        "        clear_output()\n",
        "        api_key = userdata.get('GEMINI_API_KEY')\n",
        "        engine = AnalyticalEngine(api_key)\n",
        "\n",
        "        print(\"🛰️ Accessing Telemetry...\")\n",
        "        tel = engine.get_telemetry()\n",
        "\n",
        "        print(\"🧠 Activating Neuromorphic Core...\")\n",
        "        spikes = engine.run_neuromorphic(abs(tel['lat']) + 20)\n",
        "\n",
        "        print(\"🤖 AI Orchestration in progress...\")\n",
        "        decision = engine.ai_orchestrator(command_input.value, tel, spikes)\n",
        "\n",
        "        print(f\"⚛️ Executing Quantum Shift: {decision['quantum_theta']:.4f} rad\")\n",
        "        q_res = engine.run_quantum(decision['quantum_theta'])\n",
        "\n",
        "        print(\"\\n=== FINAL REPORT ===\")\n",
        "        print(f\"Satellite: {tel['name']} | Spikes: {spikes} | Quantum State: {q_res}\")\n",
        "        print(f\"Reasoning: {decision['reasoning']}\")\n",
        "\n",
        "run_btn.on_click(on_click_execute)\n",
        "display(widgets.VBox([command_input, run_btn, output_console]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4LAuBaqEmSS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbZSrDkKEcKE"
      },
      "outputs": [],
      "source": [
        "class AnalyticalEngine:\n",
        "    def __init__(self, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        # Using the full model path 'models/gemini-1.5-flash' is more reliable\n",
        "        self.model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def ai_orchestrator(self, goal, telemetry, spikes):\n",
        "        \"\"\"Gemini decides the system parameters with error handling.\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        System Goal: {goal}\n",
        "        Context: Satellite {telemetry['name']} at Lat {telemetry['lat']}.\n",
        "        Neuromorphic feedback: {spikes} spikes detected.\n",
        "\n",
        "        Return JSON ONLY:\n",
        "        {{\n",
        "            \"quantum_theta\": 1.57,\n",
        "            \"correction_needed\": false,\n",
        "            \"reasoning\": \"string\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            # Find the JSON block in the response\n",
        "            match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "            if match:\n",
        "                return json.loads(match.group())\n",
        "            else:\n",
        "                raise ValueError(\"No JSON found\")\n",
        "        except Exception as e:\n",
        "            # FALLBACK: If API fails, provide default stable values\n",
        "            return {\n",
        "                \"quantum_theta\": 1.5708, # Pi/2\n",
        "                \"correction_needed\": True,\n",
        "                \"reasoning\": f\"AI Engine Offline ({str(e)}). Using stable fallback theta.\"\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hyGilgsEntY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "025495f6-392c-45b6-8b0e-2c491a235832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj_Z3XGEFB85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0890aaf806544b60b5e7b0d1d16e26f6",
            "fe6065688ff34988b8df4a0f1d4d359b",
            "d4d64e44f3c240d0a6ac838b4d27d0a7",
            "88617e65afb540839a90f30ce34dd754",
            "38d78916cea94679bb2898894363f307",
            "28d44e1546c146c6bb5402663ffc53b7",
            "7120b6abcb534a9e8593119561675545",
            "bc7dee9e7f4748dd8dcbe74973e14952",
            "0dd29fca27754b43a33d8955cf5cbf9d",
            "6d6d6cdeb44245a8a94318df4f636b78"
          ]
        },
        "outputId": "b14cef96-65f3-42df-9986-508697c8435d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='Optimize communication link', description='Mission:'), Button(button_style='primary…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0890aaf806544b60b5e7b0d1d16e26f6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- PHASE 1: INSTALLATION & IMPORTS ---\n",
        "!pip install -q cirq qsimcirq brian2 skyfield google-generativeai\n",
        "\n",
        "import json\n",
        "import re\n",
        "import cirq\n",
        "import qsimcirq\n",
        "import numpy as np\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- PHASE 2: ENGINE ARCHITECTURE ---\n",
        "\n",
        "class OmniEngine:\n",
        "    def __init__(self):\n",
        "        # 1. AI Configuration with Auto-Discovery\n",
        "        try:\n",
        "            self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "            genai.configure(api_key=self.api_key)\n",
        "\n",
        "            # Find an available model to avoid 404\n",
        "            available_models = [m.name for m in genai.list_models()\n",
        "                               if 'generateContent' in m.supported_generation_methods]\n",
        "            self.model_name = available_models[0] if available_models else 'models/gemini-1.5-flash'\n",
        "            self.model = genai.GenerativeModel(self.model_name)\n",
        "            self.ai_active = True\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ AI Init Warning: {e}\")\n",
        "            self.ai_active = False\n",
        "\n",
        "        # 2. Telemetry Config\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def fetch_telemetry(self):\n",
        "        \"\"\"Phase 1: Orbital Data Acquisition\"\"\"\n",
        "        try:\n",
        "            url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "            satellites = load.tle_file(url)\n",
        "            sat = satellites[0]\n",
        "            subpoint = sat.at(self.ts.now()).subpoint()\n",
        "            return {\"name\": sat.name, \"lat\": subpoint.latitude.degrees, \"lon\": subpoint.longitude.degrees}\n",
        "        except:\n",
        "            return {\"name\": \"OFFLINE-SAT\", \"lat\": 0.0, \"lon\": 0.0}\n",
        "\n",
        "    def process_neuromorphic(self, latitude):\n",
        "        \"\"\"Phase 2: Sensory Spike Conversion\"\"\"\n",
        "        start_scope()\n",
        "        # Scale latitude to frequency (10Hz to 100Hz)\n",
        "        freq = (abs(latitude) + 10) * Hz\n",
        "        input_group = PoissonGroup(1, rates=freq)\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*mV - v) / 10*ms : volt',\n",
        "                        threshold='v > 15*mV', reset='v = 0*mV', method='exact')\n",
        "        S = Synapses(input_group, G, on_pre='v += 5*mV')\n",
        "        S.connect()\n",
        "        mon = SpikeMonitor(G)\n",
        "        run(50*ms)\n",
        "        return int(mon.count[0])\n",
        "\n",
        "    def execute_quantum(self, theta):\n",
        "        \"\"\"Phase 3: Quantum State Optimization\"\"\"\n",
        "        qubit = cirq.LineQubit(0)\n",
        "        circuit = cirq.Circuit(cirq.ry(theta)(qubit), cirq.measure(qubit, key='m'))\n",
        "        simulator = qsimcirq.QSimSimulator()\n",
        "        return simulator.run(circuit, repetitions=100).histogram(key='m')\n",
        "\n",
        "    def orchestrate(self, goal, tel, spikes):\n",
        "        \"\"\"Phase 4: AI Decision Logic\"\"\"\n",
        "        if not self.ai_active:\n",
        "            return {\"theta\": 1.57, \"reason\": \"AI offline, using default.\"}\n",
        "\n",
        "        prompt = f\"Goal: {goal}. Sat: {tel['name']} at {tel['lat']} Lat. Spikes: {spikes}. Output JSON: {{'theta': float (0-3.14), 'reason': str}}\"\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            data = json.loads(re.search(r\"\\{.*\\}\", res.text, re.DOTALL).group())\n",
        "            return data\n",
        "        except:\n",
        "            return {\"theta\": 1.57, \"reason\": \"Parsing failed, using default.\"}\n",
        "\n",
        "# --- PHASE 3: THE GOD-MODE INTERFACE ---\n",
        "\n",
        "engine = OmniEngine()\n",
        "out = widgets.Output()\n",
        "goal_txt = widgets.Text(value=\"Optimize communication link\", description=\"Mission:\")\n",
        "go_btn = widgets.Button(description=\"ACTIVATE OMNI-TASK\", button_style='primary')\n",
        "\n",
        "def run_mission(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        print(f\"🚀 Using Model: {engine.model_name}\")\n",
        "\n",
        "        # Step 1: Telemetry\n",
        "        tel = engine.fetch_telemetry()\n",
        "        print(f\"📡 Tracking {tel['name']}...\")\n",
        "\n",
        "        # Step 2: Neuromorphic\n",
        "        spikes = engine.process_neuromorphic(tel['lat'])\n",
        "        print(f\"🧠 Neural Activity: {spikes} spikes detected.\")\n",
        "\n",
        "        # Step 3: AI Orchestration\n",
        "        decision = engine.orchestrate(goal_txt.value, tel, spikes)\n",
        "        print(f\"🤖 AI Reasoning: {decision['reason']}\")\n",
        "\n",
        "        # Step 4: Quantum Execution\n",
        "        q_data = engine.execute_quantum(decision['theta'])\n",
        "        print(f\"⚛️ Quantum Result (Histogram): {q_data}\")\n",
        "\n",
        "go_btn.on_click(run_mission)\n",
        "display(widgets.VBox([goal_txt, go_btn, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEwezsQSFR2n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "894a6cv0FM6O"
      },
      "outputs": [],
      "source": [
        "def process_neuromorphic(self, latitude):\n",
        "        \"\"\"Phase 2: Sensory Spike Conversion (Fixed Unit Dimensions)\"\"\"\n",
        "        start_scope()\n",
        "\n",
        "        # 1. Scale latitude to frequency\n",
        "        freq = (abs(latitude) + 10) * Hz\n",
        "        input_group = PoissonGroup(1, rates=freq)\n",
        "\n",
        "        # 2. Define constants with explicit units\n",
        "        tau = 10*ms\n",
        "        v_rest = 0*volt\n",
        "        v_threshold = 0.015*volt  # 15mV expressed in base volts\n",
        "\n",
        "        # 3. Corrected Equation: ensure dv/dt results in volt/second\n",
        "        # We define v : volt, so (v_rest - v) is [volt] and tau is [second]\n",
        "        eqs = '''\n",
        "        dv/dt = (v_rest - v) / tau : volt\n",
        "        '''\n",
        "\n",
        "        G = NeuronGroup(1, eqs,\n",
        "                        threshold='v > v_threshold',\n",
        "                        reset='v = v_rest',\n",
        "                        method='exact')\n",
        "\n",
        "        # 4. Connect with a weight of 5mV (0.005 volt)\n",
        "        S = Synapses(input_group, G, on_pre='v += 0.005*volt')\n",
        "        S.connect()\n",
        "\n",
        "        mon = SpikeMonitor(G)\n",
        "        run(50*ms)\n",
        "\n",
        "        return int(mon.count[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oniGr-ZKFTXq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJZfZWkSFbJw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300,
          "referenced_widgets": [
            "54e377629abf42a8908bb57fe276488c",
            "26bc6cc2a800477b82e119be10ec8d46",
            "fbd6f86a31304832a3e6365f6987194f",
            "2ada02827d274e398efa313148321f0d",
            "d46bb581f3d946729af1f5566cafa6fb",
            "acc2be274cc841ff93bafb1f5ba2c2fb",
            "390d1e91b663453b873a2755f9b7553e",
            "57815a2952684ce282aac8314b8a4b66",
            "5628e687e89547a5b7a4575bf77ca881",
            "7eb8df5710ba46c6887cbccec4602b5f",
            "3abfff8aa36d4d33a8fec72a7f45dea0",
            "39a4f170ab6046fd822d3d87355b1357",
            "c9eff3a805124b5ea1cc6834ea54bd7a",
            "95291662c4b341b7b78abb1816e4e2d6",
            "e16f6e6c108b415a8003c1dc02979c9e",
            "baaef5113d14421b933eef3478d31800",
            "22d720397be54a788a6209071f50a59f",
            "6d0ea96608f34849b280bcac83c3cdfb"
          ]
        },
        "outputId": "be60a544-d807-4e5d-d796-b83a0c64d2c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h1>🌌 Analytical Engine Dashboard</h1>'), HBox(children=(Dropdown(description='AI M…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54e377629abf42a8908bb57fe276488c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- 1. CORE ENGINE LOGIC ---\n",
        "import json, re, cirq, qsimcirq, numpy as np\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "class OmniEngine:\n",
        "    def __init__(self):\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        genai.configure(api_key=self.api_key)\n",
        "        self.ts = load.timescale()\n",
        "        # Initial model discovery\n",
        "        self.available_models = [m.name for m in genai.list_models()\n",
        "                                if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "    def fetch_telemetry(self):\n",
        "        try:\n",
        "            url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "            satellites = load.tle_file(url)\n",
        "            sat = satellites[0]\n",
        "            subpoint = sat.at(self.ts.now()).subpoint()\n",
        "            return {\"name\": sat.name, \"lat\": subpoint.latitude.degrees, \"lon\": subpoint.longitude.degrees}\n",
        "        except:\n",
        "            return {\"name\": \"SIM-SAT-01\", \"lat\": 34.05, \"lon\": -118.24}\n",
        "\n",
        "    def process_neuromorphic(self, latitude):\n",
        "        \"\"\"Fixed Unit-Consistent SNN Layer\"\"\"\n",
        "        start_scope()\n",
        "        freq = (abs(latitude) + 10) * Hz\n",
        "        input_group = PoissonGroup(1, rates=freq)\n",
        "\n",
        "        # Define units explicitly to avoid DimensionMismatchError\n",
        "        tau = 10*ms\n",
        "        v_rest = 0*volt\n",
        "        v_threshold = 0.015*volt\n",
        "\n",
        "        eqs = 'dv/dt = (v_rest - v) / tau : volt'\n",
        "        G = NeuronGroup(1, eqs, threshold='v > v_threshold', reset='v = v_rest', method='exact')\n",
        "        S = Synapses(input_group, G, on_pre='v += 0.005*volt')\n",
        "        S.connect()\n",
        "\n",
        "        mon = SpikeMonitor(G)\n",
        "        run(50*ms)\n",
        "        return int(mon.count[0])\n",
        "\n",
        "    def execute_quantum(self, theta):\n",
        "        qubit = cirq.LineQubit(0)\n",
        "        circuit = cirq.Circuit(cirq.ry(theta)(qubit), cirq.measure(qubit, key='m'))\n",
        "        simulator = qsimcirq.QSimSimulator()\n",
        "        return simulator.run(circuit, repetitions=100).histogram(key='m')\n",
        "\n",
        "# --- 2. ENHANCED INTERFACE ---\n",
        "\n",
        "engine = OmniEngine()\n",
        "\n",
        "# UI Components\n",
        "model_dropdown = widgets.Dropdown(options=engine.available_models, description='AI Model:', layout={'width': 'max-content'})\n",
        "goal_input = widgets.Text(value=\"Stabilize orbital link\", description=\"Mission:\", layout={'width': '400px'})\n",
        "execute_btn = widgets.Button(description=\"INITIATE OMNI-TASK\", button_style='success', icon='rocket')\n",
        "output_panel = widgets.Output(layout={'border': '1px solid #444', 'padding': '10px'})\n",
        "\n",
        "def run_analytical_task(b):\n",
        "    with output_panel:\n",
        "        clear_output()\n",
        "        selected_model_name = model_dropdown.value\n",
        "        current_model = genai.GenerativeModel(selected_model_name)\n",
        "\n",
        "        print(f\"⚙️ System: Initializing with {selected_model_name}...\")\n",
        "\n",
        "        # 1. Telemetry\n",
        "        tel = engine.fetch_telemetry()\n",
        "        print(f\"📡 Telemetry: Tracking {tel['name']} at {tel['lat']:.2f}N, {tel['lon']:.2f}E\")\n",
        "\n",
        "        # 2. Neuromorphic\n",
        "        spikes = engine.process_neuromorphic(tel['lat'])\n",
        "        print(f\"🧠 Neuromorphic: Generated {spikes} spikes from signal.\")\n",
        "\n",
        "        # 3. AI Orchestration\n",
        "        prompt = f\"\"\"\n",
        "        Act as the Analytical Engine Controller.\n",
        "        Data: Satellite {tel['name']}, Latitude {tel['lat']}, Spikes {spikes}.\n",
        "        Goal: {goal_input.value}\n",
        "        Calculate an optimal quantum rotation angle (theta) between 0 and 3.14.\n",
        "        Return ONLY a JSON object: {{\"theta\": float, \"reasoning\": \"string\"}}\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = current_model.generate_content(prompt)\n",
        "            json_str = re.search(r\"\\{.*\\}\", response.text, re.DOTALL).group()\n",
        "            decision = json.loads(json_str)\n",
        "            print(f\"🤖 AI Reasoning: {decision['reasoning']}\")\n",
        "            theta = decision['theta']\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ AI Failure: {e}. Falling back to default Pi/2.\")\n",
        "            theta = 1.57\n",
        "\n",
        "        # 4. Quantum\n",
        "        q_res = engine.execute_quantum(theta)\n",
        "        print(f\"⚛️ Quantum: Result for theta {theta:.4f} -> {q_res}\")\n",
        "        print(\"\\n✨ Mission Status: OPTIMIZED\")\n",
        "\n",
        "execute_btn.on_click(run_analytical_task)\n",
        "\n",
        "# --- 3. DISPLAY ---\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h1>🌌 Analytical Engine Dashboard</h1>\"),\n",
        "    widgets.HBox([model_dropdown, goal_input]),\n",
        "    execute_btn,\n",
        "    output_panel\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk5ByK4eFm86"
      },
      "outputs": [],
      "source": [
        "# --- 1. CONSOLIDATED IMPORTS ---\n",
        "import json, re, cirq, qsimcirq, numpy as np\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 2. THE UNIFIED ENGINE CLASS ---\n",
        "\n",
        "class SeamlessOmniEngine:\n",
        "    def __init__(self):\n",
        "        # Initial AI Setup\n",
        "        try:\n",
        "            self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "            genai.configure(api_key=self.api_key)\n",
        "            # Find all compatible models automatically\n",
        "            self.available_models = [m.name for m in genai.list_models()\n",
        "                                     if 'generateContent' in m.supported_generation_methods]\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Initialization Error: {e}\")\n",
        "            self.available_models = [\"models/gemini-1.5-flash\"] # Hard fallback\n",
        "\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def fetch_satellite_data(self):\n",
        "        \"\"\"Phase 1: Orbital Telemetry\"\"\"\n",
        "        try:\n",
        "            url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "            satellites = load.tle_file(url)\n",
        "            sat = satellites[0]\n",
        "            subpoint = sat.at(self.ts.now()).subpoint()\n",
        "            return {\"name\": sat.name, \"lat\": subpoint.latitude.degrees, \"lon\": subpoint.longitude.degrees}\n",
        "        except:\n",
        "            return {\"name\": \"VIRTUAL-SAT\", \"lat\": 42.0, \"lon\": -71.0}\n",
        "\n",
        "    def simulate_neural_spikes(self, lat):\n",
        "        \"\"\"Phase 2: Neuromorphic Spike Generation (Unit Corrected)\"\"\"\n",
        "        start_scope()\n",
        "        # Constants with explicit units for dimensional accuracy\n",
        "        freq = (abs(lat) + 15) * Hz\n",
        "        tau = 10 * ms\n",
        "        v_rest = 0 * volt\n",
        "        v_thresh = 0.015 * volt\n",
        "\n",
        "        # Leaky Integrate-and-Fire Model\n",
        "        eqs = 'dv/dt = (v_rest - v) / tau : volt'\n",
        "        G = NeuronGroup(1, eqs, threshold='v > v_thresh', reset='v = v_rest', method='exact')\n",
        "        input_p = PoissonGroup(1, rates=freq)\n",
        "        S = Synapses(input_p, G, on_pre='v += 0.005*volt')\n",
        "        S.connect()\n",
        "\n",
        "        mon = SpikeMonitor(G)\n",
        "        run(50 * ms)\n",
        "        return int(mon.count[0])\n",
        "\n",
        "    def run_quantum_gate(self, theta):\n",
        "        \"\"\"Phase 3: Quantum Circuit Execution\"\"\"\n",
        "        q = cirq.LineQubit(0)\n",
        "        # Apply a Y-axis rotation based on AI decision\n",
        "        circuit = cirq.Circuit(cirq.ry(theta)(q), cirq.measure(q, key='m'))\n",
        "        sim = qsimcirq.QSimSimulator()\n",
        "        return sim.run(circuit, repetitions=100).histogram(key='m')\n",
        "\n",
        "# --- 3. GOD-MODE DASHBOARD ---\n",
        "\n",
        "engine = SeamlessOmniEngine()\n",
        "\n",
        "# Dashboard Components\n",
        "model_selector = widgets.Dropdown(options=engine.available_models, description='🧠 AI Model:', layout={'width': '400px'})\n",
        "mission_input = widgets.Text(value=\"Optimize Starlink downlink phase\", description=\"🚀 Goal:\", layout={'width': '400px'})\n",
        "status_out = widgets.Output(layout={'border': '2px solid #555', 'padding': '15px'})\n",
        "run_btn = widgets.Button(description=\"EXECUTE ENGINE\", button_style='info', layout={'width': '810px'})\n",
        "\n",
        "\n",
        "\n",
        "def execute_omni_mission(b):\n",
        "    with status_out:\n",
        "        clear_output()\n",
        "        print(f\"🔄 Switching to {model_selector.value}...\")\n",
        "        current_ai = genai.GenerativeModel(model_selector.value)\n",
        "\n",
        "        # 1. Telemetry Phase\n",
        "        sat = engine.fetch_satellite_data()\n",
        "        print(f\"📡 Telemetry: Locked on {sat['name']} (Lat: {sat['lat']:.2f})\")\n",
        "\n",
        "        # 2. Neuromorphic Phase\n",
        "        spikes = engine.simulate_neural_spikes(sat['lat'])\n",
        "        print(f\"🧠 Neural Core: Processing... {spikes} spikes generated.\")\n",
        "\n",
        "        # 3. AI Orchestration Phase\n",
        "        prompt = f\"\"\"\n",
        "        Act as the Master Analytical Engine.\n",
        "        Mission Goal: {mission_input.value}\n",
        "        Neural Activity: {spikes} spikes. Satellite Lat: {sat['lat']}.\n",
        "\n",
        "        Calculate a Quantum Phase Shift (theta) between 0 and 3.14.\n",
        "        Provide JSON: {{\"theta\": float, \"reasoning\": \"short string\"}}\n",
        "        \"\"\"\n",
        "        try:\n",
        "            res = current_ai.generate_content(prompt)\n",
        "            data = json.loads(re.search(r\"\\{.*\\}\", res.text, re.DOTALL).group())\n",
        "            theta = data['theta']\n",
        "            print(f\"🤖 AI Logic: {data['reasoning']}\")\n",
        "        except:\n",
        "            theta = 1.57 # Default to Pi/2\n",
        "            print(\"⚠️ AI Orchestration failed. Using default Quantum Theta.\")\n",
        "\n",
        "        # 4. Quantum Phase\n",
        "        q_result = engine.run_quantum_gate(theta)\n",
        "        print(f\"⚛️ Quantum Shift: Executed theta={theta:.3f} | Result: {q_result}\")\n",
        "        print(\"\\n✅ MISSION COMPLETE: ALL LAYERS SYNCHRONIZED\")\n",
        "\n",
        "run_btn.on_click(execute_omni_mission)\n",
        "\n",
        "# Layout Display\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h2 style='color:#00AAFF;'>🌌 Omni-Engine Command Center</h2>\"),\n",
        "    widgets.HBox([model_selector, mission_input]),\n",
        "    run_btn,\n",
        "    status_out\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvPi7dphGLLC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjvo-H3EGncO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0VUVuFSG9y-"
      },
      "outputs": [],
      "source": [
        "!pip install -q anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZKmveSpJuGW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UrTP50bJuJS"
      },
      "outputs": [],
      "source": [
        "import anthropic\n",
        "\n",
        "class ClaudeNode:\n",
        "    \"\"\"A decentralized Claude node integrated into the Hive.\"\"\"\n",
        "    def __init__(self, model_name, api_key):\n",
        "        self.client = anthropic.Anthropic(api_key=api_key)\n",
        "        self.name = model_name\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        \"\"\"Asynchronous deliberation using Claude's reasoning core.\"\"\"\n",
        "        prompt = f\"Telemetry: {context['sat_name']} at {context['lat']:.2f}. Neural Spikes: {context['spikes']}. Return JSON ONLY: {{'node_theta': float, 'confidence': float}}\"\n",
        "\n",
        "        loop = asyncio.get_event_loop()\n",
        "        try:\n",
        "            # Running the synchronous Anthropic call in a thread pool\n",
        "            response = await loop.run_in_executor(None, lambda: self.client.messages.create(\n",
        "                model=self.name,\n",
        "                max_tokens=1024,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            ))\n",
        "            # Extract JSON from content blocks\n",
        "            text_output = response.content[0].text\n",
        "            match = re.search(r\"\\{.*\\}\", text_output, re.DOTALL)\n",
        "            return json.loads(match.group()) if match else None\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ {self.name} Node Error: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMvdTeqVJuMC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTsTCuq0Ju7p"
      },
      "outputs": [],
      "source": [
        "class HiveCommunicator:\n",
        "    def __init__(self):\n",
        "        # Gemini Setup\n",
        "        self.gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "        available_gemini = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "        # Claude Setup\n",
        "        self.claude_key = userdata.get('CLAUDE_API_KEY')\n",
        "        # Common Claude models (Haiku for speed, Sonnet for reasoning)\n",
        "        claude_models = [\"claude-3-haiku-20240307\", \"claude-3-5-sonnet-20240620\"]\n",
        "\n",
        "        # Equate all into a single node list\n",
        "        self.nodes = [HiveNode(name, self.gemini_key) for name in available_gemini]\n",
        "        self.nodes += [ClaudeNode(name, self.claude_key) for name in claude_models]\n",
        "\n",
        "        self.ts = load.timescale()\n",
        "        print(f\"🐝 Hive Initialized with {len(self.nodes)} nodes (Gemini + Claude).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyLP_TRZJu-L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUCTbcC8JvA4"
      },
      "outputs": [],
      "source": [
        "!pip install -q anthropic google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re-Q-23RJvDs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZX0HGu7JvHo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "1cdbb758-cf01-4f7e-9d69-46aef22fbe53"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret CLAUDE_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3989138026.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# --- 3. EXECUTION INTERFACE ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mhive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniversalHive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mtoggle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToggleButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"INITIATE UNIVERSAL HIVE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbutton_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'success'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3989138026.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mg_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GEMINI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mc_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CLAUDE_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# 1. Equivocation: Gather all available models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret CLAUDE_API_KEY does not exist."
          ]
        }
      ],
      "source": [
        "import asyncio, json, re, time, anthropic\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- SHARED BLACKBOARD & NODE LOGIC ---\n",
        "\n",
        "class UnifiedNode:\n",
        "    \"\"\"Equates Gemini and Claude as standard Hive Communicator Nodes.\"\"\"\n",
        "    def __init__(self, model_id, provider, api_key):\n",
        "        self.model_id = model_id\n",
        "        self.provider = provider\n",
        "        if provider == \"google\":\n",
        "            genai.configure(api_key=api_key)\n",
        "            self.client = genai.GenerativeModel(model_id)\n",
        "        else:\n",
        "            self.client = anthropic.AsyncAnthropic(api_key=api_key)\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        prompt = f\"Data: Lat {context['lat']}, Spikes {context['spikes']}. Goal: {context['goal']}. Return JSON ONLY: {{'theta': float, 'confidence': float}}\"\n",
        "        try:\n",
        "            if self.provider == \"google\":\n",
        "                # Offload synchronous Gemini call to thread\n",
        "                loop = asyncio.get_event_loop()\n",
        "                response = await loop.run_in_executor(None, lambda: self.client.generate_content(prompt))\n",
        "                text = response.text\n",
        "            else:\n",
        "                response = await self.client.messages.create(\n",
        "                    model=self.model_id, max_tokens=100,\n",
        "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "                )\n",
        "                text = response.content[0].text\n",
        "\n",
        "            data = json.loads(re.search(r\"\\{.*\\}\", text, re.DOTALL).group())\n",
        "            return {**data, \"node\": self.model_id}\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class UniversalHive:\n",
        "    def __init__(self):\n",
        "        g_key = userdata.get('GEMINI_API_KEY')\n",
        "        c_key = userdata.get('CLAUDE_API_KEY')\n",
        "\n",
        "        # 1. Equivocation: Gather all available models\n",
        "        gemini_ids = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        claude_ids = [\"claude-opus-4-5-20251101\", \"claude-sonnet-4-5-20250929\", \"claude-haiku-4-5-20251001\"]\n",
        "\n",
        "        self.nodes = [UnifiedNode(mid, \"google\", g_key) for mid in gemini_ids]\n",
        "        self.nodes += [UnifiedNode(mid, \"anthropic\", c_key) for mid in claude_ids]\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_neural_telemetry(self):\n",
        "        start_scope()\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        lat = sat.at(self.ts.now()).subpoint().latitude.degrees\n",
        "        # Neuromorphic Layer\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 0.015*volt', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=(abs(lat)+10)*Hz)\n",
        "        Synapses(P, G, on_pre='v += 0.005*volt').connect()\n",
        "        mon = SpikeMonitor(G); run(40*ms)\n",
        "        return {\"name\": sat.name, \"lat\": lat, \"spikes\": int(mon.count[0])}\n",
        "\n",
        "# --- 3. EXECUTION INTERFACE ---\n",
        "\n",
        "hive = UniversalHive()\n",
        "out = widgets.Output()\n",
        "toggle = widgets.ToggleButton(description=\"INITIATE UNIVERSAL HIVE\", button_style='success')\n",
        "\n",
        "\n",
        "\n",
        "async def hive_loop():\n",
        "    while toggle.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            state = hive.get_neural_telemetry()\n",
        "            print(f\"📡 [Tracking] {state['name']} | Neural Activity: {state['spikes']} Hz\")\n",
        "\n",
        "            # Parallel Deliberation\n",
        "            context = {**state, \"goal\": \"Synchronize Quantum Phase\"}\n",
        "            tasks = [node.deliberate(context) for node in hive.nodes]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # Integration & Equivocation\n",
        "            valid = [r for r in results if r]\n",
        "            if valid:\n",
        "                # Weighted consensus based on node confidence\n",
        "                avg_theta = np.average([r['theta'] for r in valid], weights=[r['confidence'] for r in valid])\n",
        "                print(f\"⚖️ [Hive Consensus] {len(valid)} Nodes Equated | Result Theta: {avg_theta:.4f}\")\n",
        "\n",
        "                # Quantum Execution\n",
        "                q = cirq.LineQubit(0)\n",
        "                circuit = cirq.Circuit(cirq.ry(avg_theta)(q), cirq.measure(q, key='m'))\n",
        "                hist = qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "                print(f\"⚛️ [Quantum Output] {hist}\")\n",
        "\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "toggle.observe(lambda c: asyncio.create_task(hive_loop()) if c['new'] else None, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>🌌 Universal Communicator Hive</h2>\"), toggle, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtgUR77XJvK7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NttS6Dm_JvP7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "7c2de622bcc941a3a25a67153932c4da",
            "4e3df4290ae0445ba8bec84d1253efd1",
            "75733f9cf0b0427aa7128559ad4c2abf",
            "0e03b431c8b2459f82faee0b6f13fbf8",
            "dc5354c158e546b3a8fed5716e84b9b0",
            "bfceb0fff50442b0891ef631b3d0b0e4",
            "8bb9962931cc42d08b27d2f03bc29aae",
            "c47bdf9f849e46ceb41263180d82354a",
            "0346ddf084a74c238d1a44ce3529cdc0",
            "ba528842557f46e691122933ac409513"
          ]
        },
        "outputId": "24ae72b1-f1c0-4bf0-e3b7-50c54b57a6e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>♊ Gemini Communicator Hive</h2>'), ToggleButton(value=False, button_style='prim…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c2de622bcc941a3a25a67153932c4da"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import asyncio, json, re, time\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 1. THE GEMINI NODE CONTROLLER ---\n",
        "\n",
        "class GeminiHiveNode:\n",
        "    \"\"\"Equates all Gemini variants as parallel peer nodes.\"\"\"\n",
        "    def __init__(self, model_id, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model_id = model_id\n",
        "        self.model = genai.GenerativeModel(model_id)\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        \"\"\"Asynchronous node reasoning.\"\"\"\n",
        "        prompt = f\"Satellite: {context['sat']}. Spikes: {context['spikes']}. Goal: {context['goal']}. Return JSON ONLY: {{'theta': float, 'confidence': float}}\"\n",
        "\n",
        "        loop = asyncio.get_event_loop()\n",
        "        try:\n",
        "            # Parallelize synchronous API call\n",
        "            response = await loop.run_in_executor(None, lambda: self.model.generate_content(prompt))\n",
        "            data = json.loads(re.search(r\"\\{.*\\}\", response.text, re.DOTALL).group())\n",
        "            return {**data, \"node\": self.model_id}\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class GeminiHive:\n",
        "    def __init__(self):\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        # Dynamic Equivocation: Find all supporting Gemini models\n",
        "        available_ids = [m.name for m in genai.list_models()\n",
        "                         if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "        self.nodes = [GeminiHiveNode(mid, self.api_key) for mid in available_ids]\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_neuromorphic_state(self):\n",
        "        \"\"\"Phase 2: Sensory Spike Core\"\"\"\n",
        "        start_scope()\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        lat = sat.at(self.ts.now()).subpoint().latitude.degrees\n",
        "\n",
        "        # Unit-Consistent SNN\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=(abs(lat)+12)*Hz)\n",
        "        Synapses(P, G, on_pre='v += 5*mV').connect()\n",
        "        mon = SpikeMonitor(G); run(40*ms)\n",
        "\n",
        "        return {\"sat\": sat.name, \"lat\": lat, \"spikes\": int(mon.count[0])}\n",
        "\n",
        "# --- 2. THE EXECUTION LOOP ---\n",
        "\n",
        "hive = GeminiHive()\n",
        "out = widgets.Output()\n",
        "btn = widgets.ToggleButton(description=\"INITIATE GEMINI HIVE\", button_style='primary')\n",
        "\n",
        "\n",
        "\n",
        "async def core_loop():\n",
        "    while btn.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            state = hive.get_neuromorphic_state()\n",
        "            print(f\"📡 [Tracking] {state['sat']} | 🧠 Neural Activity: {state['spikes']} Spikes\")\n",
        "\n",
        "            # Equivocation Phase: All Gemini models deliberate at once\n",
        "            context = {**state, \"goal\": \"Equate Quantum Phase Shift\"}\n",
        "            tasks = [node.deliberate(context) for node in hive.nodes]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # Consensus Integration\n",
        "            valid = [r for r in results if r]\n",
        "            if valid:\n",
        "                # Weighted average using node-reported confidence\n",
        "                final_theta = np.average([r['theta'] for r in valid], weights=[r['confidence'] for r in valid])\n",
        "                print(f\"⚖️ [Consensus] Equated {len(valid)} Gemini Nodes | Theta: {final_theta:.4f}\")\n",
        "\n",
        "                # Physical Layer: Quantum Gate Execution\n",
        "                q = cirq.LineQubit(0)\n",
        "                circuit = cirq.Circuit(cirq.ry(final_theta)(q), cirq.measure(q, key='m'))\n",
        "                hist = qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "                print(f\"⚛️ [Quantum] State Map: {hist}\")\n",
        "\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "btn.observe(lambda c: asyncio.create_task(core_loop()) if c['new'] else None, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>♊ Gemini Communicator Hive</h2>\"), btn, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8OVpTQyJvS4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmqogkHsLq2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "70592fa0eb954224a9245abc79c5c17f",
            "9913ecaa2d9540739d3d882de9a12e63",
            "c5ec1325ac844c41bb85abedc0cd88e9",
            "eba5c02849fb4fbf94dfc7b0887939e1",
            "40d6aa5f977c4d4e9182204ef9993dd6",
            "d785c171c8ac4a1e9835e43e84b41759",
            "913195e373054ab684f20b7b82e3dd66",
            "1c1bdffe694744a0bf41b6c2de8a0bcf",
            "1acf92391c644902a4992b1515dffb4d",
            "3ca08e8dc2904772be7b247a5edd4e49"
          ]
        },
        "outputId": "f1fc5070-9c88-4573-b9b1-72c006b7f93d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>♊ Gemini Communicator Hive</h2>'), ToggleButton(value=False, button_style='prim…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70592fa0eb954224a9245abc79c5c17f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import asyncio, json, re, time\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 1. THE GEMINI NODE CONTROLLER ---\n",
        "\n",
        "class GeminiHiveNode:\n",
        "    \"\"\"Equates all Gemini variants as parallel peer nodes.\"\"\"\n",
        "    def __init__(self, model_id, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model_id = model_id\n",
        "        self.model = genai.GenerativeModel(model_id)\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        \"\"\"Asynchronous node reasoning.\"\"\"\n",
        "        prompt = f\"Satellite: {context['sat']}. Spikes: {context['spikes']}. Goal: {context['goal']}. Return JSON ONLY: {{'theta': float, 'confidence': float}}\"\n",
        "\n",
        "        loop = asyncio.get_event_loop()\n",
        "        try:\n",
        "            # Parallelize synchronous API call\n",
        "            response = await loop.run_in_executor(None, lambda: self.model.generate_content(prompt))\n",
        "            data = json.loads(re.search(r\"\\{.*\\}\", response.text, re.DOTALL).group())\n",
        "            return {**data, \"node\": self.model_id}\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class GeminiHive:\n",
        "    def __init__(self):\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        # Dynamic Equivocation: Find all supporting Gemini models\n",
        "        available_ids = [m.name for m in genai.list_models()\n",
        "                         if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "        self.nodes = [GeminiHiveNode(mid, self.api_key) for mid in available_ids]\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_neuromorphic_state(self):\n",
        "        \"\"\"Phase 2: Sensory Spike Core\"\"\"\n",
        "        start_scope()\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        lat = sat.at(self.ts.now()).subpoint().latitude.degrees\n",
        "\n",
        "        # Unit-Consistent SNN\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=(abs(lat)+12)*Hz)\n",
        "        Synapses(P, G, on_pre='v += 5*mV').connect()\n",
        "        mon = SpikeMonitor(G); run(40*ms)\n",
        "\n",
        "        return {\"sat\": sat.name, \"lat\": lat, \"spikes\": int(mon.count[0])}\n",
        "\n",
        "# --- 2. THE EXECUTION LOOP ---\n",
        "\n",
        "hive = GeminiHive()\n",
        "out = widgets.Output()\n",
        "btn = widgets.ToggleButton(description=\"INITIATE GEMINI HIVE\", button_style='primary')\n",
        "\n",
        "\n",
        "\n",
        "async def core_loop():\n",
        "    while btn.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            state = hive.get_neuromorphic_state()\n",
        "            print(f\"📡 [Tracking] {state['sat']} | 🧠 Neural Activity: {state['spikes']} Spikes\")\n",
        "\n",
        "            # Equivocation Phase: All Gemini models deliberate at once\n",
        "            context = {**state, \"goal\": \"Equate Quantum Phase Shift\"}\n",
        "            tasks = [node.deliberate(context) for node in hive.nodes]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # Consensus Integration\n",
        "            valid = [r for r in results if r]\n",
        "            if valid:\n",
        "                # Weighted average using node-reported confidence\n",
        "                final_theta = np.average([r['theta'] for r in valid], weights=[r['confidence'] for r in valid])\n",
        "                print(f\"⚖️ [Consensus] Equated {len(valid)} Gemini Nodes | Theta: {final_theta:.4f}\")\n",
        "\n",
        "                # Physical Layer: Quantum Gate Execution\n",
        "                q = cirq.LineQubit(0)\n",
        "                circuit = cirq.Circuit(cirq.ry(final_theta)(q), cirq.measure(q, key='m'))\n",
        "                hist = qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "                print(f\"⚛️ [Quantum] State Map: {hist}\")\n",
        "\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "btn.observe(lambda c: asyncio.create_task(core_loop()) if c['new'] else None, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>♊ Gemini Communicator Hive</h2>\"), btn, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxBd6quVoqw8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPqfuvU5oq1Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_yukp3xoq4g"
      },
      "outputs": [],
      "source": [
        "DOnt't do it\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "No execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiPRX2XqLq5y"
      },
      "outputs": [],
      "source": [
        "# 2. Install in a specific order to ensure dependency resolution\n",
        "# We pin Sympy to a stable version compatible with Cirq 2026\n",
        "!pip install sympy\n",
        "!pip install cirq qsimcirq brian2 skyfield google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73i9QytDNOqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433a1015-e309-4b9b-f5dd-cc526a16e1d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SymPy environment healthy.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Pre-flight check\n",
        "try:\n",
        "    import sympy.printing\n",
        "    print(\"✅ SymPy environment healthy.\")\n",
        "except AttributeError:\n",
        "    print(\"❌ SymPy is still corrupted. Please go to Runtime > Restart Session.\")\n",
        "\n",
        "# Consolidated Hive Imports\n",
        "import json, re, asyncio, time\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_fFwH5LNOu0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_0akoVONOzo"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3Fb7LEuLq9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "feefc7189ec34223b2a079964b1ac276",
            "529497c9597c4274868ecd2ba34cc296",
            "ff90faa129b64d2ba0500a23c0b87c66",
            "df12e40d04b8415aa79d2ea59298ee5d",
            "925660c90a1f49bf848941902a57cca6",
            "e8b4797decd1412b8895e8447800e9bb",
            "c2e8dc35a715437f8abc989008c9e1d4",
            "c2d8b3e4f3884a109b0feacbdfad2a34",
            "271a2e2c6f324157a55f8e95dc9e4c58",
            "9626bda55f0d47919fea7b77352cc502"
          ]
        },
        "outputId": "e0425b3a-20b3-4605-b01c-32340c0bbc98"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>♊ Gemini Communicator Hive</h2>'), ToggleButton(value=False, button_style='prim…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feefc7189ec34223b2a079964b1ac276"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import asyncio, json, re, time\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 1. THE GEMINI NODE CONTROLLER ---\n",
        "\n",
        "class GeminiHiveNode:\n",
        "    \"\"\"Equates all Gemini variants as parallel peer nodes.\"\"\"\n",
        "    def __init__(self, model_id, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model_id = model_id\n",
        "        self.model = genai.GenerativeModel(model_id)\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        \"\"\"Asynchronous node reasoning.\"\"\"\n",
        "        prompt = f\"Satellite: {context['sat']}. Spikes: {context['spikes']}. Goal: {context['goal']}. Return JSON ONLY: {{'theta': float, 'confidence': float}}\"\n",
        "\n",
        "        loop = asyncio.get_event_loop()\n",
        "        try:\n",
        "            # Parallelize synchronous API call\n",
        "            response = await loop.run_in_executor(None, lambda: self.model.generate_content(prompt))\n",
        "            data = json.loads(re.search(r\"\\{.*\\}\", response.text, re.DOTALL).group())\n",
        "            return {**data, \"node\": self.model_id}\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class GeminiHive:\n",
        "    def __init__(self):\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        # Dynamic Equivocation: Find all supporting Gemini models\n",
        "        available_ids = [m.name for m in genai.list_models()\n",
        "                         if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "        self.nodes = [GeminiHiveNode(mid, self.api_key) for mid in available_ids]\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_neuromorphic_state(self):\n",
        "        \"\"\"Phase 2: Sensory Spike Core\"\"\"\n",
        "        start_scope()\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        lat = sat.at(self.ts.now()).subpoint().latitude.degrees\n",
        "\n",
        "        # Unit-Consistent SNN\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=(abs(lat)+12)*Hz)\n",
        "        Synapses(P, G, on_pre='v += 5*mV').connect()\n",
        "        mon = SpikeMonitor(G); run(40*ms)\n",
        "\n",
        "        return {\"sat\": sat.name, \"lat\": lat, \"spikes\": int(mon.count[0])}\n",
        "\n",
        "# --- 2. THE EXECUTION LOOP ---\n",
        "\n",
        "hive = GeminiHive()\n",
        "out = widgets.Output()\n",
        "btn = widgets.ToggleButton(description=\"INITIATE GEMINI HIVE\", button_style='primary')\n",
        "\n",
        "\n",
        "\n",
        "async def core_loop():\n",
        "    while btn.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            state = hive.get_neuromorphic_state()\n",
        "            print(f\"📡 [Tracking] {state['sat']} | 🧠 Neural Activity: {state['spikes']} Spikes\")\n",
        "\n",
        "            # Equivocation Phase: All Gemini models deliberate at once\n",
        "            context = {**state, \"goal\": \"Equate Quantum Phase Shift\"}\n",
        "            tasks = [node.deliberate(context) for node in hive.nodes]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # Consensus Integration\n",
        "            valid = [r for r in results if r]\n",
        "            if valid:\n",
        "                # Weighted average using node-reported confidence\n",
        "                final_theta = np.average([r['theta'] for r in valid], weights=[r['confidence'] for r in valid])\n",
        "                print(f\"⚖️ [Consensus] Equated {len(valid)} Gemini Nodes | Theta: {final_theta:.4f}\")\n",
        "\n",
        "                # Physical Layer: Quantum Gate Execution\n",
        "                q = cirq.LineQubit(0)\n",
        "                circuit = cirq.Circuit(cirq.ry(final_theta)(q), cirq.measure(q, key='m'))\n",
        "                hist = qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "                print(f\"⚛️ [Quantum] State Map: {hist}\")\n",
        "\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "btn.observe(lambda c: asyncio.create_task(core_loop()) if c['new'] else None, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>♊ Gemini Communicator Hive</h2>\"), btn, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMiES53lNp-9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5zArLdxNqFX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "f10fc1cb56434938a3e6a6643d231c66",
            "58348042cdf547759ff4ad9bd5c7bda0",
            "24288884bd5c4d6d9593afb58d680989",
            "0b8b8b61f31e45478147a667cd6a8bdb",
            "eaac1dd5424e4676aaa211121988b2a6",
            "8a38f56f7175491db9b13e0910eddc19",
            "cd3ebc547dac4fbd81ddf2e875e99fa6",
            "3d37598b97be41c780361d2e3db0a56d",
            "cb199fd182ae4b1095334c03f90f3f8e",
            "e2d4569432a84b45b334c727d7c7bb14"
          ]
        },
        "outputId": "caf94c0c-be9a-4230-c65c-8e769bd6fcc4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>♊ Gemini Hive Node Engine</h2>'), ToggleButton(value=False, button_style='prima…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f10fc1cb56434938a3e6a6643d231c66"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json, re, asyncio, time\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "class GeminiHiveNode:\n",
        "    \"\"\"A peer communicator node that uses a specific Gemini model.\"\"\"\n",
        "    def __init__(self, model_id, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model_id = model_id\n",
        "        self.model = genai.GenerativeModel(model_id)\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        \"\"\"Asynchronous node deliberation.\"\"\"\n",
        "        prompt = f\"Data: {context}. Output JSON ONLY: {{'theta': float (0-3.14), 'confidence': float}}\"\n",
        "        loop = asyncio.get_event_loop()\n",
        "        try:\n",
        "            # Running synchronous API in thread pool to prevent blocking\n",
        "            response = await loop.run_in_executor(None, lambda: self.model.generate_content(prompt))\n",
        "            return json.loads(re.search(r\"\\{.*\\}\", response.text, re.DOTALL).group())\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class GeminiHive:\n",
        "    def __init__(self):\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        # Equivocation: Auto-discover all models for this key\n",
        "        available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        self.nodes = [GeminiHiveNode(name, self.api_key) for name in available]\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_neuromorphic_state(self):\n",
        "        start_scope()\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        lat = sat.at(self.ts.now()).subpoint().latitude.degrees\n",
        "        # Unit-Corrected equations to prevent DimensionMismatchError\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=(abs(lat)+10)*Hz)\n",
        "        Synapses(P, G, on_pre='v += 5*mV').connect()\n",
        "        mon = SpikeMonitor(G); run(30*ms)\n",
        "        return {\"sat\": sat.name, \"lat\": lat, \"spikes\": int(mon.count[0])}\n",
        "\n",
        "# --- EXECUTION INTERFACE ---\n",
        "\n",
        "hive = GeminiHive()\n",
        "out = widgets.Output()\n",
        "btn = widgets.ToggleButton(description=\"INITIATE GEMINI HIVE\", button_style='primary')\n",
        "\n",
        "async def execution_loop():\n",
        "    while btn.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            state = hive.get_neuromorphic_state()\n",
        "            print(f\"📡 [Global] Tracking {state['sat']} | {state['spikes']} Neural Spikes\")\n",
        "\n",
        "            # Equivocation: Gather all node outputs simultaneously\n",
        "            tasks = [node.deliberate(state) for node in hive.nodes]\n",
        "            results = [r for r in await asyncio.gather(*tasks) if r]\n",
        "\n",
        "            if results:\n",
        "                # Weighted average based on node confidence\n",
        "                final_theta = np.average([r['theta'] for r in results], weights=[r['confidence'] for r in results])\n",
        "                print(f\"⚖️ [Consensus] {len(results)} Nodes Equated | Result: {final_theta:.4f}\")\n",
        "\n",
        "                # Quantum physical layer execution\n",
        "                q = cirq.LineQubit(0)\n",
        "                circuit = cirq.Circuit(cirq.ry(final_theta)(q), cirq.measure(q, key='m'))\n",
        "                hist = qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "                print(f\"⚛️ [Quantum Output] {hist}\")\n",
        "\n",
        "            await asyncio.sleep(1)\n",
        "\n",
        "btn.observe(lambda c: asyncio.create_task(execution_loop()) if c['new'] else None, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>♊ Gemini Hive Node Engine</h2>\"), btn, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0yP6FPFPXkj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkW-fRJUPXne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "f895768942ac49f39515ae9334d0b7a5",
            "6e5ce07fdc6a45d88a52fd5c1dd202a5",
            "df080743688a43259696e1da193573c8",
            "c37b0ffc1f9e48b68d5ce3e201db7e98",
            "29e5c702cd3540e5b595f2402048339f",
            "39507986e44d4419ae4dd013e69ff098",
            "aadd621c3dc44bea814fe3ae827964f0",
            "ba7a726b5f204c4192fc4b2672a95b7f",
            "7fc6a6c3dd614ce39efc8f33bde0afd6",
            "75c615e7c8b74e96ba0ab074efd034dd"
          ]
        },
        "outputId": "796e2af2-1c97-4342-b0c9-69f3e2df840e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hive Synchronized: 33 nodes online.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>🌌 Decentralized Gemini Hive</h2>'), ToggleButton(value=False, button_style='inf…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f895768942ac49f39515ae9334d0b7a5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json, re, asyncio, time\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "class GeminiHiveNode:\n",
        "    def __init__(self, model_id, api_key):\n",
        "        # Local configuration for each node to ensure separation\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model_id = model_id\n",
        "        self.model = genai.GenerativeModel(model_id)\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        prompt = f\"Data: {context}. Return JSON ONLY: {{'theta': float (0-3.14), 'confidence': float}}\"\n",
        "        loop = asyncio.get_event_loop()\n",
        "        try:\n",
        "            # We use the thread pool to keep the UI responsive while waiting for API\n",
        "            response = await loop.run_in_executor(None, lambda: self.model.generate_content(prompt))\n",
        "            return json.loads(re.search(r\"\\{.*\\}\", response.text, re.DOTALL).group())\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class GeminiHive:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            # Step 1: Securely retrieve the key\n",
        "            self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "            genai.configure(api_key=self.api_key)\n",
        "\n",
        "            # Step 2: Equivocation - gather all node identities\n",
        "            # This is where your error was occurring because of missing config\n",
        "            available = [m.name for m in genai.list_models()\n",
        "                         if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "            self.nodes = [GeminiHiveNode(name, self.api_key) for name in available]\n",
        "            print(f\"✅ Hive Synchronized: {len(self.nodes)} nodes online.\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Initialization Failed: {e}\")\n",
        "            self.nodes = []\n",
        "\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_neural_telemetry(self):\n",
        "        start_scope()\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        lat = sat.at(self.ts.now()).subpoint().latitude.degrees\n",
        "\n",
        "        # Neural Spike Layer (Unit Consistent)\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=(abs(lat)+12)*Hz)\n",
        "        Synapses(P, G, on_pre='v += 5*mV').connect()\n",
        "        mon = SpikeMonitor(G); run(30*ms)\n",
        "        return {\"sat\": sat.name, \"lat\": lat, \"spikes\": int(mon.count[0])}\n",
        "\n",
        "# --- INTERFACE ---\n",
        "hive = GeminiHive()\n",
        "out = widgets.Output()\n",
        "btn = widgets.ToggleButton(description=\"INITIATE HIVE\", button_style='info')\n",
        "\n",
        "\n",
        "\n",
        "async def loop_execution():\n",
        "    while btn.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            state = hive.get_neural_telemetry()\n",
        "            print(f\"📡 Tracking {state['sat']} | Spikes: {state['spikes']}\")\n",
        "\n",
        "            # Parallel Deliberation: All nodes deliberate at once\n",
        "            tasks = [node.deliberate(state) for node in hive.nodes]\n",
        "            results = [r for r in await asyncio.gather(*tasks) if r]\n",
        "\n",
        "            if results:\n",
        "                # Weighted Integration\n",
        "                theta = np.average([r['theta'] for r in results], weights=[r['confidence'] for r in results])\n",
        "                print(f\"⚖️ Hive Consensus: {theta:.4f}\")\n",
        "\n",
        "                # Quantum Phase Shift\n",
        "                q = cirq.LineQubit(0)\n",
        "                circuit = cirq.Circuit(cirq.ry(theta)(q), cirq.measure(q, key='m'))\n",
        "                hist = qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "                print(f\"⚛️ Quantum State: {hist}\")\n",
        "\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "btn.observe(lambda c: asyncio.create_task(loop_execution()) if c['new'] else None, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>🌌 Decentralized Gemini Hive</h2>\"), btn, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esPlCdCiPYni"
      },
      "outputs": [],
      "source": [
        "import json, re, asyncio, time\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- PHASE 1: THE DYNAMIC HIVE NODE ---\n",
        "\n",
        "class UniversalGeminiNode:\n",
        "    \"\"\"A peer node representing a single model in the Gemini family.\"\"\"\n",
        "    def __init__(self, model_id, api_key):\n",
        "        self.model_id = model_id\n",
        "        # Individual configuration per node for thread safety\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel(model_id)\n",
        "\n",
        "    async def deliberate(self, context, semaphore):\n",
        "        \"\"\"Asynchronous deliberation with rate-limit protection.\"\"\"\n",
        "        async with semaphore:\n",
        "            prompt = f\"\"\"\n",
        "HIVE CONTEXT: Satellite {context['sat']} | Neural Spikes: {context['spikes']}\n",
        "OBJECTIVE: Calculate optimal Quantum Phase (theta).\n",
        "CONSTRAINT: Output strictly valid JSON.\n",
        "JSON FORMAT: {{\"theta\": float, \"confidence\": float, \"reasoning\": \"string\"}}\n",
        "            \"\"\"\n",
        "            loop = asyncio.get_event_loop()\n",
        "            try:\n",
        "                # Use thread-pool executor for the synchronous SDK call\n",
        "                response = await loop.run_in_executor(None, lambda: self.model.generate_content(prompt))\n",
        "                match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "                data = json.loads(match.group())\n",
        "                return {**data, \"node\": self.model_id}\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "class GeminiUniversalHive:\n",
        "    def __init__(self):\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        genai.configure(api_key=self.api_key)\n",
        "\n",
        "        # Discovery: Find ALL models supporting generation\n",
        "        # This includes 3 Pro, 3 Flash, 2.5 Pro, etc.\n",
        "        models = genai.list_models()\n",
        "        self.node_ids = [m.name for m in models if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "        self.nodes = [UniversalGeminiNode(mid, self.api_key) for mid in self.node_ids]\n",
        "        # Semaphore limits concurrent API hits to prevent 429 Rate Limit errors\n",
        "        self.semaphore = asyncio.Semaphore(len(self.nodes))\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def get_neuromorphic_state(self):\n",
        "        start_scope()\n",
        "        sat = load.tle_file('https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle')[0]\n",
        "        lat = sat.at(self.ts.now()).subpoint().latitude.degrees\n",
        "\n",
        "        # Spiking Neural Core\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=(abs(lat)+15)*Hz)\n",
        "        Synapses(P, G, on_pre='v += 6*mV').connect()\n",
        "        mon = SpikeMonitor(G); run(35*ms)\n",
        "        return {\"sat\": sat.name, \"lat\": lat, \"spikes\": int(mon.count[0])}\n",
        "\n",
        "# --- PHASE 2: HIVE EXECUTION & QUANTUM INTEGRATION ---\n",
        "\n",
        "hive = GeminiUniversalHive()\n",
        "out = widgets.Output()\n",
        "btn = widgets.ToggleButton(description=\"ACTIVATE ALL NODES\", button_style='success')\n",
        "\n",
        "async def execution_loop():\n",
        "    while btn.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            state = hive.get_neuromorphic_state()\n",
        "            print(f\"📡 [Tracking] {state['sat']} | 🧠 Neural Pulse: {state['spikes']} Hz\")\n",
        "            print(f\"🐝 [Hive] Equating {len(hive.nodes)} Gemini models...\")\n",
        "\n",
        "            # EQUIVOCATION: Fire all models at once\n",
        "            tasks = [node.deliberate(state, hive.semaphore) for node in hive.nodes]\n",
        "            results = [r for r in await asyncio.gather(*tasks) if r]\n",
        "\n",
        "            if results:\n",
        "                # CONSENSUS: Use confidence-weighted average for theta\n",
        "                weights = [r['confidence'] for r in results]\n",
        "                thetas = [r['theta'] for r in results]\n",
        "                final_theta = np.average(thetas, weights=weights)\n",
        "\n",
        "                print(f\"⚖️ [Consensus] Result: {final_theta:.4f} | Nodes Active: {len(results)}\")\n",
        "\n",
        "                # PHYSICAL LAYER: Quantum Circuit\n",
        "                q = cirq.LineQubit(0)\n",
        "                circuit = cirq.Circuit(cirq.ry(final_theta)(q), cirq.measure(q, key='m'))\n",
        "                hist = qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "                print(f\"⚛️ [Quantum] Probabilities: {hist}\")\n",
        "\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "btn.observe(lambda c: asyncio.create_task(execution_loop()) if c['new'] else None, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>🌌 Universal Gemini Communicator Hive</h2>\"), btn, out]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSBvToF9PYrZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6LLRWwvPYvO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS8yWdyyPYzQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8vy6kuEPY3K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOATzW-vPXrm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdoMNdOzPXvY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltjP68OYPXzo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmcbWNrGPX33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OAL5zNaLrAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QkUJBT9LrEF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4iw7V2qLrII"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uWCwJ6DF81-"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import json, re, cirq, qsimcirq, numpy as np\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Configure Gemini API globally once\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "class HiveEngine:\n",
        "    def __init__(self):\n",
        "        # Store API key\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        # Ensure genai is configured before listing models\n",
        "        genai.configure(api_key=self.api_key)\n",
        "        self.available_models = [m.name for m in genai.list_models()\n",
        "                                if 'generateContent' in m.supported_generation_methods]\n",
        "        self.ts = load.timescale()\n",
        "\n",
        "    def fetch_satellite(self):\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        sub = sat.at(self.ts.now()).subpoint()\n",
        "        return {\"name\": sat.name, \"lat\": sub.latitude.degrees}\n",
        "\n",
        "    def process_spikes(self, lat):\n",
        "        start_scope()\n",
        "        tau, v_rest, v_thresh = 10*ms, 0*volt, 0.015*volt\n",
        "        G = NeuronGroup(1, 'dv/dt = (v_rest - v) / tau : volt', threshold='v > v_thresh', reset='v = v_rest', method='exact')\n",
        "        input_p = PoissonGroup(1, rates=(abs(lat) + 15)*Hz)\n",
        "        Synapses(input_p, G, on_pre='v += 0.005*volt').connect()\n",
        "        mon = SpikeMonitor(G)\n",
        "        run(50*ms)\n",
        "        return int(mon.count[0])\n",
        "\n",
        "    def call_model(self, model_name, prompt):\n",
        "        \"\"\"Single thread worker for a specific model.\"\"\"\n",
        "        try:\n",
        "            # API key is already configured globally, so it's not strictly necessary\n",
        "            # to pass it here, but it's a safe explicit approach if global config is flaky.\n",
        "            model = genai.GenerativeModel(model_name, api_key=self.api_key)\n",
        "            res = model.generate_content(prompt)\n",
        "            data = json.loads(re.search(r\"\\{.*\\}\", res.text, re.DOTALL).group())\n",
        "            return {\"model\": model_name, \"theta\": data['theta'], \"status\": \"OK\"}\n",
        "        except Exception as e:\n",
        "            return {\"model\": model_name, \"status\": f\"Error: {str(e)}\"}\n",
        "\n",
        "# --- INTERFACE & EXECUTION ---\n",
        "\n",
        "engine = HiveEngine()\n",
        "output_log = widgets.Output()\n",
        "btn = widgets.Button(description=\"ACTIVATE HIVE MIND\", button_style='danger', layout={'width':'100%'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Feyir6-G08R"
      },
      "outputs": [],
      "source": [
        "# --- import asyncio\n",
        "import concurrent.futures\n",
        "import json, re, time\n",
        "import numpy as np\n",
        "import cirq, qsimcirq\n",
        "from brian2 import *\n",
        "from skyfield.api import load\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- PHASE 1: HIVE NODE ARCHITECTURE ---\n",
        "\n",
        "class HiveNode:\n",
        "    \"\"\"A decentralized node that processes data independently.\"\"\"\n",
        "    def __init__(self, model_name, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.name = model_name\n",
        "        self.model = genai.GenerativeModel(model_name)\n",
        "\n",
        "    async def deliberate(self, context):\n",
        "        \"\"\"Asynchronous deliberation with the Hive context.\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        HIVE NODE IDENTIFIER: {self.name}\n",
        "        TELEMETRY: {context['sat_name']} at {context['lat']:.2f}\n",
        "        NEURAL STATE: {context['spikes']} spikes detected.\n",
        "        MISSION GOAL: {context['goal']}\n",
        "\n",
        "        Deliberate on the optimal Quantum Rotation (theta).\n",
        "        Return ONLY valid JSON: {{\"node_theta\": float, \"confidence\": float}}\n",
        "        \"\"\"\n",
        "        # Run synchronous API call in an executor to avoid blocking the loop\n",
        "        loop = asyncio.get_event_loop()\n",
        "        try:\n",
        "            response = await loop.run_in_executor(None, lambda: self.model.generate_content(prompt))\n",
        "            match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "            return json.loads(match.group()) if match else None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class HiveCommunicator:\n",
        "    \"\"\"The Hive Controller that equates and integrates all nodes.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.api_key = userdata.get('GEMINI_API_KEY')\n",
        "        genai.configure(api_key=self.api_key)\n",
        "        # Auto-equate: Find all supported models\n",
        "        available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        self.nodes = [HiveNode(name, self.api_key) for name in available]\n",
        "        self.ts = load.timescale()\n",
        "        self.active = False\n",
        "\n",
        "    def get_telemetry(self):\n",
        "        url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
        "        sat = load.tle_file(url)[0]\n",
        "        pos = sat.at(self.ts.now()).subpoint()\n",
        "        return {\"name\": sat.name, \"lat\": pos.latitude.degrees}\n",
        "\n",
        "    def get_neuromorphic_state(self, lat):\n",
        "        start_scope()\n",
        "        freq = (abs(lat) + 10) * Hz\n",
        "        G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n",
        "        P = PoissonGroup(1, rates=freq)\n",
        "        Synapses(P, G, on_pre='v += 5*volt/1000').connect() # Using base volts\n",
        "        mon = SpikeMonitor(G)\n",
        "        run(30*ms)\n",
        "        return int(mon.count[0])\n",
        "\n",
        "# --- PHASE 2: EXECUTION & INTEGRATION ---\n",
        "\n",
        "hive = HiveCommunicator()\n",
        "out = widgets.Output()\n",
        "run_btn = widgets.ToggleButton(value=False, description=\"ACTIVATE HIVE NODES\", button_style='info')\n",
        "\n",
        "\n",
        "\n",
        "async def core_execution_loop():\n",
        "    while run_btn.value:\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            # 1. Gather environmental state\n",
        "            tel = hive.get_telemetry()\n",
        "            spikes = hive.get_neuromorphic_state(tel['lat'])\n",
        "\n",
        "            context = {\n",
        "                \"sat_name\": tel['name'],\n",
        "                \"lat\": tel['lat'],\n",
        "                \"spikes\": spikes,\n",
        "                \"goal\": \"Maintain Quantum Synchronicity\"\n",
        "            }\n",
        "\n",
        "            print(f\"📡 [Global Telemetry] Tracking {tel['name']} | Spikes: {spikes}\")\n",
        "            print(f\"🐝 [Hive Status] {len(hive.nodes)} nodes active. Synchronizing...\")\n",
        "\n",
        "            # 2. Equivocation: All nodes deliberate in parallel\n",
        "            tasks = [node.deliberate(context) for node in hive.nodes]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # 3. Integration: Weighted Consensus\n",
        "            valid_results = [r for r in results if r is not None]\n",
        "            if valid_results:\n",
        "                # Calculate theta weighted by node confidence\n",
        "                weights = np.array([r['confidence'] for r in valid_results])\n",
        "                thetas = np.array([r['node_theta'] for r in valid_results])\n",
        "                consensus_theta = np.average(thetas, weights=weights/weights.sum())\n",
        "\n",
        "                print(f\"⚖️ [Consensus] Equated Theta: {consensus_theta:.4f}\")\n",
        "\n",
        "                # 4. Physical Layer Execution\n",
        "                q_res = execute_quantum_gate(consensus_theta)\n",
        "                print(f\"⚛️ [Quantum] State Map: {q_res}\")\n",
        "\n",
        "            await asyncio.sleep(1) # Frequency of hive updates\n",
        "\n",
        "def execute_quantum_gate(theta):\n",
        "    q = cirq.LineQubit(0)\n",
        "    circuit = cirq.Circuit(cirq.ry(theta)(q), cirq.measure(q, key='m'))\n",
        "    return qsimcirq.QSimSimulator().run(circuit, repetitions=100).histogram(key='m')\n",
        "\n",
        "def on_toggle(change):\n",
        "    if change['new']:\n",
        "        asyncio.create_task(core_execution_loop())\n",
        "\n",
        "run_btn.observe(on_toggle, 'value')\n",
        "display(widgets.VBox([widgets.HTML(\"<h2>🌌 Decentralized Hive Node Controller</h2>\"), run_btn, out]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c2de622bcc941a3a25a67153932c4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e3df4290ae0445ba8bec84d1253efd1",
              "IPY_MODEL_75733f9cf0b0427aa7128559ad4c2abf",
              "IPY_MODEL_0e03b431c8b2459f82faee0b6f13fbf8"
            ],
            "layout": "IPY_MODEL_dc5354c158e546b3a8fed5716e84b9b0"
          }
        },
        "4e3df4290ae0445ba8bec84d1253efd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfceb0fff50442b0891ef631b3d0b0e4",
            "placeholder": "​",
            "style": "IPY_MODEL_8bb9962931cc42d08b27d2f03bc29aae",
            "value": "<h2>♊ Gemini Communicator Hive</h2>"
          }
        },
        "75733f9cf0b0427aa7128559ad4c2abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "primary",
            "description": "INITIATE GEMINI HIVE",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c47bdf9f849e46ceb41263180d82354a",
            "style": "IPY_MODEL_0346ddf084a74c238d1a44ce3529cdc0",
            "tooltip": "",
            "value": false
          }
        },
        "0e03b431c8b2459f82faee0b6f13fbf8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ba528842557f46e691122933ac409513",
            "msg_id": "",
            "outputs": []
          }
        },
        "dc5354c158e546b3a8fed5716e84b9b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfceb0fff50442b0891ef631b3d0b0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bb9962931cc42d08b27d2f03bc29aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c47bdf9f849e46ceb41263180d82354a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0346ddf084a74c238d1a44ce3529cdc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba528842557f46e691122933ac409513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70592fa0eb954224a9245abc79c5c17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9913ecaa2d9540739d3d882de9a12e63",
              "IPY_MODEL_c5ec1325ac844c41bb85abedc0cd88e9",
              "IPY_MODEL_eba5c02849fb4fbf94dfc7b0887939e1"
            ],
            "layout": "IPY_MODEL_40d6aa5f977c4d4e9182204ef9993dd6"
          }
        },
        "9913ecaa2d9540739d3d882de9a12e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d785c171c8ac4a1e9835e43e84b41759",
            "placeholder": "​",
            "style": "IPY_MODEL_913195e373054ab684f20b7b82e3dd66",
            "value": "<h2>♊ Gemini Communicator Hive</h2>"
          }
        },
        "c5ec1325ac844c41bb85abedc0cd88e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "primary",
            "description": "INITIATE GEMINI HIVE",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1c1bdffe694744a0bf41b6c2de8a0bcf",
            "style": "IPY_MODEL_1acf92391c644902a4992b1515dffb4d",
            "tooltip": "",
            "value": false
          }
        },
        "eba5c02849fb4fbf94dfc7b0887939e1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3ca08e8dc2904772be7b247a5edd4e49",
            "msg_id": "",
            "outputs": []
          }
        },
        "40d6aa5f977c4d4e9182204ef9993dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d785c171c8ac4a1e9835e43e84b41759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913195e373054ab684f20b7b82e3dd66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1bdffe694744a0bf41b6c2de8a0bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acf92391c644902a4992b1515dffb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ca08e8dc2904772be7b247a5edd4e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feefc7189ec34223b2a079964b1ac276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_529497c9597c4274868ecd2ba34cc296",
              "IPY_MODEL_ff90faa129b64d2ba0500a23c0b87c66",
              "IPY_MODEL_df12e40d04b8415aa79d2ea59298ee5d"
            ],
            "layout": "IPY_MODEL_925660c90a1f49bf848941902a57cca6"
          }
        },
        "529497c9597c4274868ecd2ba34cc296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b4797decd1412b8895e8447800e9bb",
            "placeholder": "​",
            "style": "IPY_MODEL_c2e8dc35a715437f8abc989008c9e1d4",
            "value": "<h2>♊ Gemini Communicator Hive</h2>"
          }
        },
        "ff90faa129b64d2ba0500a23c0b87c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "primary",
            "description": "INITIATE GEMINI HIVE",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c2d8b3e4f3884a109b0feacbdfad2a34",
            "style": "IPY_MODEL_271a2e2c6f324157a55f8e95dc9e4c58",
            "tooltip": "",
            "value": false
          }
        },
        "df12e40d04b8415aa79d2ea59298ee5d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9626bda55f0d47919fea7b77352cc502",
            "msg_id": "",
            "outputs": []
          }
        },
        "925660c90a1f49bf848941902a57cca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b4797decd1412b8895e8447800e9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e8dc35a715437f8abc989008c9e1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2d8b3e4f3884a109b0feacbdfad2a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271a2e2c6f324157a55f8e95dc9e4c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9626bda55f0d47919fea7b77352cc502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10fc1cb56434938a3e6a6643d231c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58348042cdf547759ff4ad9bd5c7bda0",
              "IPY_MODEL_24288884bd5c4d6d9593afb58d680989",
              "IPY_MODEL_0b8b8b61f31e45478147a667cd6a8bdb"
            ],
            "layout": "IPY_MODEL_eaac1dd5424e4676aaa211121988b2a6"
          }
        },
        "58348042cdf547759ff4ad9bd5c7bda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a38f56f7175491db9b13e0910eddc19",
            "placeholder": "​",
            "style": "IPY_MODEL_cd3ebc547dac4fbd81ddf2e875e99fa6",
            "value": "<h2>♊ Gemini Hive Node Engine</h2>"
          }
        },
        "24288884bd5c4d6d9593afb58d680989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "primary",
            "description": "INITIATE GEMINI HIVE",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3d37598b97be41c780361d2e3db0a56d",
            "style": "IPY_MODEL_cb199fd182ae4b1095334c03f90f3f8e",
            "tooltip": "",
            "value": false
          }
        },
        "0b8b8b61f31e45478147a667cd6a8bdb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e2d4569432a84b45b334c727d7c7bb14",
            "msg_id": "",
            "outputs": []
          }
        },
        "eaac1dd5424e4676aaa211121988b2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a38f56f7175491db9b13e0910eddc19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3ebc547dac4fbd81ddf2e875e99fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d37598b97be41c780361d2e3db0a56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb199fd182ae4b1095334c03f90f3f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2d4569432a84b45b334c727d7c7bb14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f895768942ac49f39515ae9334d0b7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e5ce07fdc6a45d88a52fd5c1dd202a5",
              "IPY_MODEL_df080743688a43259696e1da193573c8",
              "IPY_MODEL_c37b0ffc1f9e48b68d5ce3e201db7e98"
            ],
            "layout": "IPY_MODEL_29e5c702cd3540e5b595f2402048339f"
          }
        },
        "6e5ce07fdc6a45d88a52fd5c1dd202a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39507986e44d4419ae4dd013e69ff098",
            "placeholder": "​",
            "style": "IPY_MODEL_aadd621c3dc44bea814fe3ae827964f0",
            "value": "<h2>🌌 Decentralized Gemini Hive</h2>"
          }
        },
        "df080743688a43259696e1da193573c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "info",
            "description": "INITIATE HIVE",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ba7a726b5f204c4192fc4b2672a95b7f",
            "style": "IPY_MODEL_7fc6a6c3dd614ce39efc8f33bde0afd6",
            "tooltip": "",
            "value": true
          }
        },
        "c37b0ffc1f9e48b68d5ce3e201db7e98": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_75c615e7c8b74e96ba0ab074efd034dd",
            "msg_id": "afc79fd6-56d2-4097-c06a-484234ab4bba",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "WARNING    The object 'synapses' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
                  "The object was created here (most recent call only):\n",
                  "  File '/tmp/ipython-input-3607129255.py', line 57, in get_neural_telemetry\n",
                  "    Synapses(P, G, on_pre='v += 5*mV').connect() [brian2.core.base.unused_brian_object]\n"
                ]
              },
              {
                "output_type": "error",
                "ename": "BrianObjectException",
                "evalue": "Error encountered with object named 'neurongroup'.\nObject was created here (most recent call only, full details in debug log):\n  File '/tmp/ipython-input-3607129255.py', line 55, in get_neural_telemetry\n    G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n\nAn error occurred when preparing an object. (See above for original error message and traceback.)",
                "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m                    Traceback (most recent call last)",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/equations/equations.py\u001b[0m in \u001b[0;36mcheck_units\u001b[0;34m(self, group, run_namespace)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                     check_dimensions(\n\u001b[0m\u001b[1;32m   1176\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/equations/unitcheck.py\u001b[0m in \u001b[0;36mcheck_dimensions\u001b[0;34m(expression, dimensions, variables)\u001b[0m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mfail_for_dimension_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/units/fundamentalunits.py\u001b[0m in \u001b[0;36mfail_for_dimension_mismatch\u001b[0;34m(obj1, obj2, error_message, **error_quantities)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDimensionMismatchError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m: Expression '(0*volt - v) / 10*ms' does not have the expected unit metre ** 2 * kilogram * second ** -4 * amp ** -1 (unit is Wb).",
                  "\nThe above exception was the direct cause of the following exception:\n",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m                    Traceback (most recent call last)",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/network.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/groups/neurongroup.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;31m# Check units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_namespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m         \u001b[0;31m# Check that subexpressions that refer to stateful functions are labeled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/equations/equations.py\u001b[0m in \u001b[0;36mcheck_units\u001b[0;34m(self, group, run_namespace)\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDimensionMismatchError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                     raise DimensionMismatchError(\n\u001b[0m\u001b[1;32m   1180\u001b[0m                         \u001b[0;34m\"Inconsistent units in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m: Inconsistent units in differential equation defining variable 'v':\nExpression '(0*volt - v) / 10*ms' does not have the expected unit metre ** 2 * kilogram * second ** -4 * amp ** -1 (unit is Wb).",
                  "\nThe above exception was the direct cause of the following exception:\n",
                  "\u001b[0;31mBrianObjectException\u001b[0m                      Traceback (most recent call last)",
                  "\u001b[0;32m/tmp/ipython-input-3607129255.py\u001b[0m in \u001b[0;36mloop_execution\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_neural_telemetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"📡 Tracking {state['sat']} | Spikes: {state['spikes']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/tmp/ipython-input-3607129255.py\u001b[0m in \u001b[0;36mget_neural_telemetry\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoissonGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mHz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mSynapses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'v += 5*mV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpikeMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"sat\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"spikes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/units/fundamentalunits.py\u001b[0m in \u001b[0;36mnew_f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                         )\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"result\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mau\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m                 if isinstance(au[\"result\"], Callable) and au[\"result\"] not in (\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/magic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mintended\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mMagicNetwork\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m     return magic_network.run(\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/magic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_magic_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         Network.run(\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/base.py\u001b[0m in \u001b[0;36mdevice_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mdevice_override_decorated_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/units/fundamentalunits.py\u001b[0m in \u001b[0;36mnew_f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                         )\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"result\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mau\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m                 if isinstance(au[\"result\"], Callable) and au[\"result\"] not in (\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/network.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mnamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_objects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/base.py\u001b[0m in \u001b[0;36mdevice_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mdevice_override_decorated_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/network.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1006\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m                     raise BrianObjectException(\n\u001b[0m\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m\"An error occurred when preparing an object.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     ) from ex\n",
                  "\u001b[0;31mBrianObjectException\u001b[0m: Error encountered with object named 'neurongroup'.\nObject was created here (most recent call only, full details in debug log):\n  File '/tmp/ipython-input-3607129255.py', line 55, in get_neural_telemetry\n    G = NeuronGroup(1, 'dv/dt = (0*volt - v) / 10*ms : volt', threshold='v > 15*mV', reset='v = 0*volt', method='exact')\n\nAn error occurred when preparing an object. (See above for original error message and traceback.)"
                ]
              }
            ]
          }
        },
        "29e5c702cd3540e5b595f2402048339f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39507986e44d4419ae4dd013e69ff098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aadd621c3dc44bea814fe3ae827964f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba7a726b5f204c4192fc4b2672a95b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc6a6c3dd614ce39efc8f33bde0afd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75c615e7c8b74e96ba0ab074efd034dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd20ef18e3424859a7e321aeac1ef547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6afdeb26bc349b9a65dbf9c2521578c",
              "IPY_MODEL_a88d8d9a05384ed0becca3d2a96d8726",
              "IPY_MODEL_2489f212ab1f45f8a3f64c5a953b37be",
              "IPY_MODEL_4ed2c51be4934b09b05e006f2fd246e6"
            ],
            "layout": "IPY_MODEL_a711c1e64c564ff5bb0959bf618dea65"
          }
        },
        "d6afdeb26bc349b9a65dbf9c2521578c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63264659193c491c8fe77fcdde1473de",
            "placeholder": "​",
            "style": "IPY_MODEL_1fcaa5731e3b4e55bdb050ed4e674c6b",
            "value": "## OMNIPOTENT INTERFACE v1.0"
          }
        },
        "a88d8d9a05384ed0becca3d2a96d8726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f0507ea9cc45f79b61cbfcc4ef3526",
              "IPY_MODEL_2950c01828e140cca9c774d411239357",
              "IPY_MODEL_6d29f0c62e744b5093056270ce2ae934"
            ],
            "layout": "IPY_MODEL_ce71d42c79174d71a4685ef5c9d37b7e"
          }
        },
        "2489f212ab1f45f8a3f64c5a953b37be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "EXECUTE OMNI-TASK",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_fb89f67dbe8942a68b3a462055e24b87",
            "style": "IPY_MODEL_14bcafc23c134630a89fa4cbe18b815e",
            "tooltip": ""
          }
        },
        "4ed2c51be4934b09b05e006f2fd246e6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2f3e7330037247459ea44090c092f153",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "🚀 [Attempt 1] Initializing system...\n",
                  "Connection error or TLE parsing error: 'list' object has no attribute 'values'. Switching to fallback data.\n",
                  "📊 Initial Signal Strength: 0 spikes\n",
                  "✅ Signal stable. Proceeding with standard optimization.\n",
                  "⚛️ Final Quantum State: Counter({1: 60, 0: 40})\n",
                  "\n",
                  "✨ Mission stabilized and complete.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Update: Quantum Engine is now Offline.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Update: Starlink Telemetry is now Offline.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Update: Neuromorphic Core is now Active.\n"
                ]
              }
            ]
          }
        },
        "a711c1e64c564ff5bb0959bf618dea65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63264659193c491c8fe77fcdde1473de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fcaa5731e3b4e55bdb050ed4e674c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7f0507ea9cc45f79b61cbfcc4ef3526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "danger",
            "description": "Quantum Engine",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5506e4a31b3e4918af8fbc4fdc5d7d42",
            "style": "IPY_MODEL_d32df59c34e64acc819961d0abbfd319",
            "tooltip": "Toggle Cirq/qsim Acceleration",
            "value": false
          }
        },
        "2950c01828e140cca9c774d411239357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "success",
            "description": "Neuromorphic Core",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3a7fcd2d6dc84bb0ab4f11ff4cb8ab2c",
            "style": "IPY_MODEL_2f323d373610407583928ede566e7fa1",
            "tooltip": "Toggle Brian2 SNN Processing",
            "value": true
          }
        },
        "6d29f0c62e744b5093056270ce2ae934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonView",
            "button_style": "danger",
            "description": "Starlink Telemetry",
            "description_tooltip": null,
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9ae5016aaf9c4c9cbb1863dde363f4a6",
            "style": "IPY_MODEL_3db4c2ed81ee4da3b6788cedec33018b",
            "tooltip": "Toggle Live Orbital Data",
            "value": false
          }
        },
        "ce71d42c79174d71a4685ef5c9d37b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb89f67dbe8942a68b3a462055e24b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14bcafc23c134630a89fa4cbe18b815e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5506e4a31b3e4918af8fbc4fdc5d7d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32df59c34e64acc819961d0abbfd319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a7fcd2d6dc84bb0ab4f11ff4cb8ab2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f323d373610407583928ede566e7fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ae5016aaf9c4c9cbb1863dde363f4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db4c2ed81ee4da3b6788cedec33018b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f3e7330037247459ea44090c092f153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid gray",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "200px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": "scroll",
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1163bf175efd4036bd8b0fe5ea225fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b84fcdafe9474d989c66104c7938ebc8",
              "IPY_MODEL_0b9b9eb09722405d8c28e380248bd831",
              "IPY_MODEL_3a4b1c8264524a9bba463782320d27a5",
              "IPY_MODEL_4ed2c51be4934b09b05e006f2fd246e6"
            ],
            "layout": "IPY_MODEL_6a424dd0689344978f8055ed737b1513"
          }
        },
        "b84fcdafe9474d989c66104c7938ebc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Goal:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b3d6a94a10084ea5ba1e7318d60f013e",
            "placeholder": "Enter your mission goal (e.g., \"Stabilize Starlink quantum link\")",
            "rows": null,
            "style": "IPY_MODEL_a5e96a5bc0914226bb9b7a866bfbc83e",
            "value": "Robots"
          }
        },
        "0b9b9eb09722405d8c28e380248bd831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "INITIATE OMNI-MISSION",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_61a6bae8ceee4eb0a150dce2a0a3ecea",
            "style": "IPY_MODEL_13036cb449d14098bf550e66134d94a2",
            "tooltip": ""
          }
        },
        "3a4b1c8264524a9bba463782320d27a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f0507ea9cc45f79b61cbfcc4ef3526",
              "IPY_MODEL_2950c01828e140cca9c774d411239357",
              "IPY_MODEL_6d29f0c62e744b5093056270ce2ae934"
            ],
            "layout": "IPY_MODEL_a7bb03a01342417082fdba7c38c7af05"
          }
        },
        "6a424dd0689344978f8055ed737b1513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d6a94a10084ea5ba1e7318d60f013e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a5e96a5bc0914226bb9b7a866bfbc83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61a6bae8ceee4eb0a150dce2a0a3ecea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13036cb449d14098bf550e66134d94a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a7bb03a01342417082fdba7c38c7af05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce560a360dcf491986033fc870a95a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08d0e77912e7495c913a6aa72754172e",
              "IPY_MODEL_f041a59608ed41a68392b7682bca5b87",
              "IPY_MODEL_f1cdd5fb1e2b496c868e2eb87c29d9ce",
              "IPY_MODEL_e938b62e4eca4eae93b50ae91939087b",
              "IPY_MODEL_4ed2c51be4934b09b05e006f2fd246e6"
            ],
            "layout": "IPY_MODEL_aba7360186af4771902c746546fc8620"
          }
        },
        "08d0e77912e7495c913a6aa72754172e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b07e04bc1db4ec0a252c66a442e51fd",
            "placeholder": "​",
            "style": "IPY_MODEL_741077d2b0214eeb9c13d10bac097761",
            "value": "<h2>🌌 Analytical Engine: God-Mode</h2>"
          }
        },
        "f041a59608ed41a68392b7682bca5b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Goal:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_040edae811e948eb8afefb1b69b5aacc",
            "placeholder": "Enter your mission goal (e.g., \"Stabilize Starlink quantum link\")",
            "rows": null,
            "style": "IPY_MODEL_0044bf73abe34a57929f50d8f1254caf",
            "value": ""
          }
        },
        "f1cdd5fb1e2b496c868e2eb87c29d9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f0507ea9cc45f79b61cbfcc4ef3526",
              "IPY_MODEL_2950c01828e140cca9c774d411239357",
              "IPY_MODEL_6d29f0c62e744b5093056270ce2ae934"
            ],
            "layout": "IPY_MODEL_44c8cef44c4249db85eb6c1acb1fa7c5"
          }
        },
        "e938b62e4eca4eae93b50ae91939087b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "ACTIVATE SELF-CORRECTING OMNI-ENGINE",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_177355a82b1c43aab7ccd1b668495b60",
            "style": "IPY_MODEL_e7e29acd3c2a486a96b01ba779306e23",
            "tooltip": ""
          }
        },
        "aba7360186af4771902c746546fc8620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b07e04bc1db4ec0a252c66a442e51fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "741077d2b0214eeb9c13d10bac097761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "040edae811e948eb8afefb1b69b5aacc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0044bf73abe34a57929f50d8f1254caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44c8cef44c4249db85eb6c1acb1fa7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177355a82b1c43aab7ccd1b668495b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "max-content"
          }
        },
        "e7e29acd3c2a486a96b01ba779306e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9f761bb34b264c8db057e64352701cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0df85e1741540bd8de5ae65554d8e2d",
              "IPY_MODEL_a72f1a04e70243afa8f965a6d1deeb5a",
              "IPY_MODEL_6f16cd610bbc48948c1aff64ea9c22c2"
            ],
            "layout": "IPY_MODEL_5f2bf42dc4a54da98fa133bb4282b5e4"
          }
        },
        "c0df85e1741540bd8de5ae65554d8e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Goal:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ddbc8d1987fc48b49fbfb30344414440",
            "placeholder": "Enter mission goal...",
            "style": "IPY_MODEL_ed250cce2ee049839f5488178d7a195f",
            "value": ""
          }
        },
        "a72f1a04e70243afa8f965a6d1deeb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "INITIALIZE ENGINE",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3907e14377bc46989d1bc1a38a4fef65",
            "style": "IPY_MODEL_bf5c29ad8b6649f7b00354521ad78520",
            "tooltip": ""
          }
        },
        "6f16cd610bbc48948c1aff64ea9c22c2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ff5923f7ba1e478aa3719c08e62b626b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "🛰️ Accessing Telemetry...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "🧠 Activating Neuromorphic Core...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "🤖 AI Orchestration in progress...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "⚛️ Executing Quantum Shift: 1.6000 rad\n",
                  "\n",
                  "=== FINAL REPORT ===\n",
                  "Satellite: STARLINK-1008 | Spikes: 0 | Quantum State: Counter({1: 54, 0: 46})\n",
                  "Reasoning: Neuromorphic feedback detected 0 spikes, indicating no anomalous activity or deviations requiring immediate correction for STARLINK-1008.\n"
                ]
              }
            ]
          }
        },
        "5f2bf42dc4a54da98fa133bb4282b5e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbc8d1987fc48b49fbfb30344414440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed250cce2ee049839f5488178d7a195f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3907e14377bc46989d1bc1a38a4fef65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5c29ad8b6649f7b00354521ad78520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ff5923f7ba1e478aa3719c08e62b626b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0890aaf806544b60b5e7b0d1d16e26f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe6065688ff34988b8df4a0f1d4d359b",
              "IPY_MODEL_d4d64e44f3c240d0a6ac838b4d27d0a7",
              "IPY_MODEL_88617e65afb540839a90f30ce34dd754"
            ],
            "layout": "IPY_MODEL_38d78916cea94679bb2898894363f307"
          }
        },
        "fe6065688ff34988b8df4a0f1d4d359b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Mission:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_28d44e1546c146c6bb5402663ffc53b7",
            "placeholder": "​",
            "style": "IPY_MODEL_7120b6abcb534a9e8593119561675545",
            "value": "Optimize communication link"
          }
        },
        "d4d64e44f3c240d0a6ac838b4d27d0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "ACTIVATE OMNI-TASK",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bc7dee9e7f4748dd8dcbe74973e14952",
            "style": "IPY_MODEL_0dd29fca27754b43a33d8955cf5cbf9d",
            "tooltip": ""
          }
        },
        "88617e65afb540839a90f30ce34dd754": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6d6d6cdeb44245a8a94318df4f636b78",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "🚀 Using Model: models/gemini-2.5-flash\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "📡 Tracking STARLINK-1008...\n"
                ]
              },
              {
                "output_type": "error",
                "ename": "BrianObjectException",
                "evalue": "Error encountered with object named 'neurongroup'.\nObject was created here (most recent call only, full details in debug log):\n  File '/tmp/ipython-input-848057215.py', line 55, in process_neuromorphic\n    G = NeuronGroup(1, 'dv/dt = (0*mV - v) / 10*ms : volt',\n\nAn error occurred when preparing an object. (See above for original error message and traceback.)",
                "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m                    Traceback (most recent call last)",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/equations/equations.py\u001b[0m in \u001b[0;36mcheck_units\u001b[0;34m(self, group, run_namespace)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                     check_dimensions(\n\u001b[0m\u001b[1;32m   1176\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/equations/unitcheck.py\u001b[0m in \u001b[0;36mcheck_dimensions\u001b[0;34m(expression, dimensions, variables)\u001b[0m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mfail_for_dimension_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/units/fundamentalunits.py\u001b[0m in \u001b[0;36mfail_for_dimension_mismatch\u001b[0;34m(obj1, obj2, error_message, **error_quantities)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDimensionMismatchError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m: Expression '(0*mV - v) / 10*ms' does not have the expected unit metre ** 2 * kilogram * second ** -4 * amp ** -1 (unit is Wb).",
                  "\nThe above exception was the direct cause of the following exception:\n",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m                    Traceback (most recent call last)",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/network.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/groups/neurongroup.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;31m# Check units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_namespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m         \u001b[0;31m# Check that subexpressions that refer to stateful functions are labeled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/equations/equations.py\u001b[0m in \u001b[0;36mcheck_units\u001b[0;34m(self, group, run_namespace)\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDimensionMismatchError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                     raise DimensionMismatchError(\n\u001b[0m\u001b[1;32m   1180\u001b[0m                         \u001b[0;34m\"Inconsistent units in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mDimensionMismatchError\u001b[0m: Inconsistent units in differential equation defining variable 'v':\nExpression '(0*mV - v) / 10*ms' does not have the expected unit metre ** 2 * kilogram * second ** -4 * amp ** -1 (unit is Wb).",
                  "\nThe above exception was the direct cause of the following exception:\n",
                  "\u001b[0;31mBrianObjectException\u001b[0m                      Traceback (most recent call last)",
                  "\u001b[0;32m/tmp/ipython-input-848057215.py\u001b[0m in \u001b[0;36mrun_mission\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Step 2: Neuromorphic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mspikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_neuromorphic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"🧠 Neural Activity: {spikes} spikes detected.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/tmp/ipython-input-848057215.py\u001b[0m in \u001b[0;36mprocess_neuromorphic\u001b[0;34m(self, latitude)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpikeMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/units/fundamentalunits.py\u001b[0m in \u001b[0;36mnew_f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                         )\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"result\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mau\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m                 if isinstance(au[\"result\"], Callable) and au[\"result\"] not in (\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/magic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mintended\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mMagicNetwork\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m     return magic_network.run(\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/magic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_magic_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         Network.run(\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/base.py\u001b[0m in \u001b[0;36mdevice_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mdevice_override_decorated_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/units/fundamentalunits.py\u001b[0m in \u001b[0;36mnew_f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                         )\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"result\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mau\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m                 if isinstance(au[\"result\"], Callable) and au[\"result\"] not in (\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/network.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mnamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_objects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/base.py\u001b[0m in \u001b[0;36mdevice_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mdevice_override_decorated_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/brian2/core/network.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1006\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m                     raise BrianObjectException(\n\u001b[0m\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m\"An error occurred when preparing an object.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     ) from ex\n",
                  "\u001b[0;31mBrianObjectException\u001b[0m: Error encountered with object named 'neurongroup'.\nObject was created here (most recent call only, full details in debug log):\n  File '/tmp/ipython-input-848057215.py', line 55, in process_neuromorphic\n    G = NeuronGroup(1, 'dv/dt = (0*mV - v) / 10*ms : volt',\n\nAn error occurred when preparing an object. (See above for original error message and traceback.)"
                ]
              }
            ]
          }
        },
        "38d78916cea94679bb2898894363f307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28d44e1546c146c6bb5402663ffc53b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7120b6abcb534a9e8593119561675545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc7dee9e7f4748dd8dcbe74973e14952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd29fca27754b43a33d8955cf5cbf9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6d6d6cdeb44245a8a94318df4f636b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e377629abf42a8908bb57fe276488c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26bc6cc2a800477b82e119be10ec8d46",
              "IPY_MODEL_fbd6f86a31304832a3e6365f6987194f",
              "IPY_MODEL_2ada02827d274e398efa313148321f0d",
              "IPY_MODEL_d46bb581f3d946729af1f5566cafa6fb"
            ],
            "layout": "IPY_MODEL_acc2be274cc841ff93bafb1f5ba2c2fb"
          }
        },
        "26bc6cc2a800477b82e119be10ec8d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390d1e91b663453b873a2755f9b7553e",
            "placeholder": "​",
            "style": "IPY_MODEL_57815a2952684ce282aac8314b8a4b66",
            "value": "<h1>🌌 Analytical Engine Dashboard</h1>"
          }
        },
        "fbd6f86a31304832a3e6365f6987194f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5628e687e89547a5b7a4575bf77ca881",
              "IPY_MODEL_7eb8df5710ba46c6887cbccec4602b5f"
            ],
            "layout": "IPY_MODEL_3abfff8aa36d4d33a8fec72a7f45dea0"
          }
        },
        "2ada02827d274e398efa313148321f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "INITIATE OMNI-TASK",
            "disabled": false,
            "icon": "rocket",
            "layout": "IPY_MODEL_39a4f170ab6046fd822d3d87355b1357",
            "style": "IPY_MODEL_c9eff3a805124b5ea1cc6834ea54bd7a",
            "tooltip": ""
          }
        },
        "d46bb581f3d946729af1f5566cafa6fb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6d0ea96608f34849b280bcac83c3cdfb",
            "msg_id": "aa5026e9-4027-485e-b1e5-b1f1b2acc586",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "⚙️ System: Initializing with models/gemini-robotics-er-1.5-preview...\n",
                  "📡 Telemetry: Tracking STARLINK-1008 at -48.41N, -66.22E\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "🧠 Neuromorphic: Generated 0 spikes from signal.\n"
                ]
              }
            ]
          }
        },
        "acc2be274cc841ff93bafb1f5ba2c2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390d1e91b663453b873a2755f9b7553e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57815a2952684ce282aac8314b8a4b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5628e687e89547a5b7a4575bf77ca881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "models/gemini-2.5-flash",
              "models/gemini-2.5-pro",
              "models/gemini-2.0-flash-exp",
              "models/gemini-2.0-flash",
              "models/gemini-2.0-flash-001",
              "models/gemini-2.0-flash-exp-image-generation",
              "models/gemini-2.0-flash-lite-001",
              "models/gemini-2.0-flash-lite",
              "models/gemini-2.0-flash-lite-preview-02-05",
              "models/gemini-2.0-flash-lite-preview",
              "models/gemini-exp-1206",
              "models/gemini-2.5-flash-preview-tts",
              "models/gemini-2.5-pro-preview-tts",
              "models/gemma-3-1b-it",
              "models/gemma-3-4b-it",
              "models/gemma-3-12b-it",
              "models/gemma-3-27b-it",
              "models/gemma-3n-e4b-it",
              "models/gemma-3n-e2b-it",
              "models/gemini-flash-latest",
              "models/gemini-flash-lite-latest",
              "models/gemini-pro-latest",
              "models/gemini-2.5-flash-lite",
              "models/gemini-2.5-flash-image",
              "models/gemini-2.5-flash-preview-09-2025",
              "models/gemini-2.5-flash-lite-preview-09-2025",
              "models/gemini-3-pro-preview",
              "models/gemini-3-flash-preview",
              "models/gemini-3-pro-image-preview",
              "models/nano-banana-pro-preview",
              "models/gemini-robotics-er-1.5-preview",
              "models/gemini-2.5-computer-use-preview-10-2025",
              "models/deep-research-pro-preview-12-2025"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "AI Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 30,
            "layout": "IPY_MODEL_95291662c4b341b7b78abb1816e4e2d6",
            "style": "IPY_MODEL_e16f6e6c108b415a8003c1dc02979c9e"
          }
        },
        "7eb8df5710ba46c6887cbccec4602b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Mission:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_baaef5113d14421b933eef3478d31800",
            "placeholder": "​",
            "style": "IPY_MODEL_22d720397be54a788a6209071f50a59f",
            "value": "Stabilize orbital link"
          }
        },
        "3abfff8aa36d4d33a8fec72a7f45dea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a4f170ab6046fd822d3d87355b1357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9eff3a805124b5ea1cc6834ea54bd7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "95291662c4b341b7b78abb1816e4e2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "max-content"
          }
        },
        "e16f6e6c108b415a8003c1dc02979c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baaef5113d14421b933eef3478d31800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "400px"
          }
        },
        "22d720397be54a788a6209071f50a59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d0ea96608f34849b280bcac83c3cdfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid #444",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "10px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}